---
title: "Descriptives"
author: "Laura SÃ¸rine Voldgaard"
date: "2024-12-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# libraries
pacman::p_load(tidyverse, extrafont, cowplot, stringr)
```

```{r}
# load data
sd <- read.csv("descriptives_results_df.csv")
```


```{r}
mean(sd$n_tokens)
```


```{r}
# Filter out rows with n_stop_words > 5000
sd_filtered <- subset(sd, n_tokens <= 2000)

# Check the result
print(sd_filtered)
```


```{r}
# Create the histogram
distribution_article_lengths <- ggplot(sd_filtered, aes(x = n_tokens)) +
  geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
  labs(
    title = "Distribution of Article Lengths",
    x = "Words",
    y = "Number of Articles"
  ) +
  theme_minimal()
distribution_article_lengths
```
```{r}
# save plot
ggsave("distribution_article_lengths.png", plot = distribution_article_lengths, width = 8, height = 6, dpi = 300)  # Save as PNG
```





```{r}
ggplot(sd_filtered, aes(y = n_stop_words)) +
  geom_boxplot(fill = "lightgreen", color = "black") +
  labs(
    title = "Boxplot of Article Lengths",
    y = "Number of Stop Words",
    x = ""
  ) +
  theme_minimal()

```

```{r}
ggplot(sd, aes(y = n_stop_words)) +
  geom_violin(fill = "lightblue", color = "black") +
  labs(
    title = "Violin Plot of Article Lengths",
    y = "Number of Stop Words",
    x = ""
  ) +
  theme_minimal()
```




------------------------------------------

*Manual assessment*



```{r}
# load data
df <- read.csv("word_token_counts_df.csv")
```

```{r}
mean(df$word_count)
```

```{r}
mean(df$token_count)
```







```{r}
# filter outliers
cleaned_token_count <- subset(df, token_count <= 2800)

# Create the histogram
distribution_article_lengths <- ggplot(cleaned_token_count, aes(x = token_count)) +
  geom_histogram(binwidth = 50, fill = "darkcyan", color = "darkgreen") +
  labs(
    title = "Distribution of Article Lengths",
    x = "N Tokens (subwords)",
    y = "N Articles"
  ) +
  theme_minimal()
distribution_article_lengths
```


```{r}
# Load the ggplot2 library
library(ggplot2)

# Example data: Replace this with your actual token counts
token_counts <- data.frame(
  token_count = c(100, 150, 200, 180, 250, 300, 400, 100, 90, 110, 500, 600)
)

# Calculate mean and median
mean_token_count <- mean(token_counts$token_count)
median_token_count <- median(token_counts$token_count)

# 1. Histogram
histogram_plot <- ggplot(token_counts, aes(x = token_count)) +
  geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
  geom_vline(xintercept = mean_token_count, color = "red", linetype = "dashed", size = 1) +
  geom_vline(xintercept = median_token_count, color = "green", linetype = "dashed", size = 1) +
  labs(
    title = "Histogram of Token Lengths",
    x = "Token Count",
    y = "Frequency"
  ) +
  theme_minimal()

# 2. Density Plot
density_plot <- ggplot(token_counts, aes(x = token_count)) +
  geom_density(fill = "blue", alpha = 0.3) +
  geom_vline(xintercept = mean_token_count, color = "red", linetype = "dashed", size = 1) +
  geom_vline(xintercept = median_token_count, color = "green", linetype = "dashed", size = 1) +
  labs(
    title = "Density Plot of Token Lengths",
    x = "Token Count",
    y = "Density"
  ) +
  theme_minimal()

# 3. Boxplot
boxplot <- ggplot(token_counts, aes(y = token_count)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(
    title = "Boxplot of Token Lengths",
    y = "Token Count"
  ) +
  theme_minimal()

# Display the plots
print(histogram_plot)
print(density_plot)
print(boxplot)

```

```{r}
# Assuming `cleaned_token_count` is your data frame with the "token_count" column
library(ggplot2)

# Calculate the mean token length
mean_token_length <- mean(cleaned_token_count$token_count)

# Create the density plot
distribution_article_lengths <- ggplot(cleaned_token_count, aes(x = token_count)) +
  geom_density(fill = "darkcyan", alpha = 0.4) +  # Add density plot
  geom_vline(xintercept = 384, linetype = "dotted", color = "red", size = 1, show.legend = FALSE) +  # Line at 384
  geom_vline(xintercept = 512, linetype = "dotted", color = "blue", size = 1, show.legend = FALSE) +  # Line at 512
  geom_vline(xintercept = mean_token_length, linetype = "dotted", color = "darkgreen", size = 1, show.legend = FALSE) +  # Line at mean
  labs(
    title = "Distribution of Article Lengths",
    x = "Number of Tokens (Subwords)",
    y = "Density"
  ) +
  theme_minimal()

# Display the plot
distribution_article_lengths

```







```{r}
library(ggplot2)

# Assuming `cleaned_token_count` is your data frame with a "token_count" column

# Add an "article index" column for the x-axis
cleaned_token_count$article_index <- seq_len(nrow(cleaned_token_count))

# Create the bar plot
bar_plot <- ggplot(cleaned_token_count, aes(x = article_index, y = token_count)) +
  geom_bar(stat = "identity", color = "lightblue", alpha = 0.7) +  # Bars for each article
  geom_hline(yintercept = 384, linetype = "dotted", color = "red", size = 1, show.legend = FALSE) +  # Line at 384
  geom_hline(yintercept = 512, linetype = "dotted", color = "purple", size = 1, show.legend = FALSE) +  # Line at 512
  annotate("text", x = max(cleaned_token_count$article_index) * 0.5, y = 512, 
           label = "DeBERTa token limit: 512", color = "purple", size = 3.5, vjust = -1, hjust = -0.5) +  # Annotation for 512
  annotate("text", x = max(cleaned_token_count$article_index) * 0.5, y = 384, 
           label = "MPNet token limit: 384", color = "red", size = 3.5, vjust = 2, hjust = 1) +  # Annotation for 384
  labs(
    title = "Article Token Lengths with Truncation Cutoffs",
    x = "Article Index",
    y = "Token Length"
  ) +
  theme_minimal()

# Display the plot
bar_plot

```



```{r}
# save plot
ggsave("bar_plot.png", plot = bar_plot, width = 8, height = 6, dpi = 300)  # Save as PNG
```


















