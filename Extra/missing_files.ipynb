{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b2840f-6086-4678-b6a6-534440a8cb6a",
   "metadata": {},
   "source": [
    "# Purpose of notebook: inspect suspect months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb52a8f6-a947-4174-abef-b9df900b4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## install\n",
    "%pip install pandas\n",
    "%pip install chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712ef761-82e0-4941-b91f-5d06c8b6b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e9128-b3ca-4f94-a2f0-aca21149b314",
   "metadata": {},
   "source": [
    "## 21-08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d27ded-6b1c-45e4-bee4-dd7633f5a9ae",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1aafddc-4ecd-4946-a2b1-3d2b498de570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33086945</td>\n",
       "      <td>735</td>\n",
       "      <td>21-08-01</td>\n",
       "      <td>US</td>\n",
       "      <td>forbes.com</td>\n",
       "      <td>https://www.forbes.com/sites/michaelalpiner/20...</td>\n",
       "      <td>Lackawanna Coal Mine Tour Offers Travelers A R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33086946</td>\n",
       "      <td>1185</td>\n",
       "      <td>21-08-01</td>\n",
       "      <td>US</td>\n",
       "      <td>forbes.com</td>\n",
       "      <td>https://www.forbes.com/sites/splunk/2021/08/01...</td>\n",
       "      <td>Modernizing The Mission: How Data Innovation B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33086959</td>\n",
       "      <td>227</td>\n",
       "      <td>21-08-01</td>\n",
       "      <td>US</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>https://www.npr.org/programs/morning-edition/2...</td>\n",
       "      <td>Morning Edition for July 29, 2021 : NPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33086961</td>\n",
       "      <td>506</td>\n",
       "      <td>21-08-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcnews.com</td>\n",
       "      <td>https://www.nbcnews.com/politics/congress/sena...</td>\n",
       "      <td>Senate introduces the details of the bipartisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33086966</td>\n",
       "      <td>1034</td>\n",
       "      <td>21-08-01</td>\n",
       "      <td>US</td>\n",
       "      <td>theringer.com</td>\n",
       "      <td>https://www.theringer.com/nba/2021/7/28/225989...</td>\n",
       "      <td>Could Trading for Buddy Hield Put LeBron and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150007</th>\n",
       "      <td>87855805</td>\n",
       "      <td>233</td>\n",
       "      <td>21-08-31</td>\n",
       "      <td>US</td>\n",
       "      <td>WFMZ-TV</td>\n",
       "      <td>https://www.wfmz.com/sports/hartford-holds-rea...</td>\n",
       "      <td>Hartford holds Reading scoreless, wins 1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150008</th>\n",
       "      <td>87855806</td>\n",
       "      <td>1789</td>\n",
       "      <td>21-08-31</td>\n",
       "      <td>US</td>\n",
       "      <td>W magazine</td>\n",
       "      <td>https://www.wmagazine.com/culture/christopher-...</td>\n",
       "      <td>Christopher Meloni and Lewis Hamilton Share a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150009</th>\n",
       "      <td>87855807</td>\n",
       "      <td>921</td>\n",
       "      <td>21-08-31</td>\n",
       "      <td>US</td>\n",
       "      <td>WMUR9</td>\n",
       "      <td>https://www.wmur.com/article/nh-health-provide...</td>\n",
       "      <td>NH health providers prepare for booster shots ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150010</th>\n",
       "      <td>87855808</td>\n",
       "      <td>923</td>\n",
       "      <td>21-08-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahoo.com/lifestyle/10-delicious-f...</td>\n",
       "      <td>10 Delicious Fall Food Tours Across the U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150011</th>\n",
       "      <td>87855810</td>\n",
       "      <td>554</td>\n",
       "      <td>21-08-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahoo.com/lifestyle/stop-motion-tr...</td>\n",
       "      <td>Stop-Motion Trick Skiing Short Is a Mystifying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150012 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  words      date country         source  \\\n",
       "0       33086945    735  21-08-01      US     forbes.com   \n",
       "1       33086946   1185  21-08-01      US     forbes.com   \n",
       "2       33086959    227  21-08-01      US        npr.org   \n",
       "3       33086961    506  21-08-01      US    nbcnews.com   \n",
       "4       33086966   1034  21-08-01      US  theringer.com   \n",
       "...          ...    ...       ...     ...            ...   \n",
       "150007  87855805    233  21-08-31      US        WFMZ-TV   \n",
       "150008  87855806   1789  21-08-31      US     W magazine   \n",
       "150009  87855807    921  21-08-31      US          WMUR9   \n",
       "150010  87855808    923  21-08-31      US          Yahoo   \n",
       "150011  87855810    554  21-08-31      US          Yahoo   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.forbes.com/sites/michaelalpiner/20...   \n",
       "1       https://www.forbes.com/sites/splunk/2021/08/01...   \n",
       "2       https://www.npr.org/programs/morning-edition/2...   \n",
       "3       https://www.nbcnews.com/politics/congress/sena...   \n",
       "4       https://www.theringer.com/nba/2021/7/28/225989...   \n",
       "...                                                   ...   \n",
       "150007  https://www.wfmz.com/sports/hartford-holds-rea...   \n",
       "150008  https://www.wmagazine.com/culture/christopher-...   \n",
       "150009  https://www.wmur.com/article/nh-health-provide...   \n",
       "150010  https://www.yahoo.com/lifestyle/10-delicious-f...   \n",
       "150011  https://www.yahoo.com/lifestyle/stop-motion-tr...   \n",
       "\n",
       "                                                 headline  \n",
       "0       Lackawanna Coal Mine Tour Offers Travelers A R...  \n",
       "1       Modernizing The Mission: How Data Innovation B...  \n",
       "2                 Morning Edition for July 29, 2021 : NPR  \n",
       "3       Senate introduces the details of the bipartisa...  \n",
       "4       Could Trading for Buddy Hield Put LeBron and t...  \n",
       "...                                                   ...  \n",
       "150007         Hartford holds Reading scoreless, wins 1-0  \n",
       "150008  Christopher Meloni and Lewis Hamilton Share a ...  \n",
       "150009  NH health providers prepare for booster shots ...  \n",
       "150010       10 Delicious Fall Food Tours Across the U.S.  \n",
       "150011  Stop-Motion Trick Skiing Short Is a Mystifying...  \n",
       "\n",
       "[150012 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-21-08.txt\"  # Replace 'your_file_name.txt' with the actual file name\n",
    "\n",
    "# check if the path is a valid file and ends with '.txt'\n",
    "if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "    try:\n",
    "        # read the file into a dataframe, skipping bad lines\n",
    "        sources_21_08 = pd.read_csv(\n",
    "            file_path, \n",
    "            delimiter='\\t', \n",
    "            encoding='ISO-8859-1',\n",
    "            on_bad_lines='skip'  # Skip lines with too many or too few fields\n",
    "        )\n",
    "        \n",
    "        # define and assign column names\n",
    "        column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "        sources_21_08.columns = column_names\n",
    "        \n",
    "        # display the dataframe\n",
    "        sources_21_08\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError in file: {file_path}\")\n",
    "        print(e)\n",
    "        # log the problematic file\n",
    "        with open(\"/work/LauraSørineVoldgaard#8191/problematic_files.log\", \"a\") as log_file:\n",
    "            log_file.write(f\"ParserError in file: {file_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error in file: {file_path}. Error: {e}\")\n",
    "else:\n",
    "    print(f\"The specified file does not exist or is not a '.txt' file: {file_path}\")\n",
    "\n",
    "\n",
    "sources_21_08\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_21_08 = sources_21_08[sources_21_08[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_21_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e6bb0c1-9c16-45c0-97bf-3e950fbdbe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/sus_sources/sources_21_08_susnomore.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sources_21_08.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152c066-efe9-4dfb-95ce-b81653bd623a",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44bf5655-a359-4558-8a74-b1acdcb82d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          textID                                               body\n",
      "0       33086700  A duplicate content penalty can devastate your...\n",
      "1       33086701  Minnesota businesses raised nearly $500 millio...\n",
      "2       33086911  Just two months after the Vessel, a honeycomb-...\n",
      "3       33087001  TOKYO ( AP ) -- Marcell Jacobs won the men's O...\n",
      "4       33087004  On Saturday, a fleet of Jamaican sprinters swe...\n",
      "...          ...                                                ...\n",
      "154406  87855788  New analysis of office activity in July shows ...\n",
      "154407  87855794  Offensive coordinator Zach Grossiduring, right...\n",
      "154408  87855795  What role do loyalty schemes and personalizati...\n",
      "154409  87855798  The Twilight actress, 31, will star as Diana i...\n",
      "154410  87855799  Sponsored content. Us Weekly receives compensa...\n",
      "\n",
      "[154411 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-21-08/21-08-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-21-08/21-08-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-21-08/21-08-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-21-08/21-08-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-21-08/21-08-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_21_08 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(text_21_08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e8bd55d-0dba-48df-8084-ddbc9f1c2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>sources</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-08</td>\n",
       "      <td>150012</td>\n",
       "      <td>154411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  sources   texts\n",
       "0  21-08   150012  154411"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\"],  # Column for the month\n",
    "    \"sources\": [len(sources_21_08)],  # Number of rows in sources_21_08\n",
    "    \"texts\": [len(text_21_08)]  # Number of rows in text_21_08\n",
    "})\n",
    "\n",
    "sus_months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3a92-7d18-433e-bf30-887d417da764",
   "metadata": {},
   "source": [
    "## 22-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4897ff-cd06-490e-85f0-750293d2d57a",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8ed1a09-f16c-43f7-9a4b-430f67d79892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89996010</td>\n",
       "      <td>1177</td>\n",
       "      <td>22-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>The Baltimore Sun</td>\n",
       "      <td>https://www.baltimoresun.com/education/bs-md-j...</td>\n",
       "      <td>Minority students make up a small fraction of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89996011</td>\n",
       "      <td>923</td>\n",
       "      <td>22-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>ABC</td>\n",
       "      <td>https://abcnews.go.com/Sports/wireStory/corum-...</td>\n",
       "      <td>Corum, McCarthy lead No. 4 Michigan past Iowa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89996012</td>\n",
       "      <td>981</td>\n",
       "      <td>22-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>https://apnews.com/2098f5cb7ebb4fcd42bfccd6f5a...</td>\n",
       "      <td>Raleigh's walk-off homer ends Mariners' long p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89996013</td>\n",
       "      <td>534</td>\n",
       "      <td>22-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>https://apnews.com/49ca6d17cf1c8e0a8eae8f33de5...</td>\n",
       "      <td>Max Baer, Pennsylvania Supreme Court's chief j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89996014</td>\n",
       "      <td>602</td>\n",
       "      <td>22-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>https://apnews.com/9186f70b3fb426c70d4f8948296...</td>\n",
       "      <td>US women's basketball dominates on internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87591</th>\n",
       "      <td>90136835</td>\n",
       "      <td>430</td>\n",
       "      <td>22-10-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>https://markets.businessinsider.com/news/stock...</td>\n",
       "      <td>Full Truck Alliance Co. Ltd. Announces Gross T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87592</th>\n",
       "      <td>90136708</td>\n",
       "      <td>274</td>\n",
       "      <td>22-10-31</td>\n",
       "      <td>US</td>\n",
       "      <td>ABC</td>\n",
       "      <td>https://abcnews.go.com/Business/wireStory/week...</td>\n",
       "      <td>This Week: Fed meeting, Starbucks earns, jobs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87593</th>\n",
       "      <td>90136710</td>\n",
       "      <td>260</td>\n",
       "      <td>22-10-31</td>\n",
       "      <td>US</td>\n",
       "      <td>ABC</td>\n",
       "      <td>https://abcnews.go.com/US/dead-chattanooga-sho...</td>\n",
       "      <td>2 dead in Chattanooga shooting, police say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>90136713</td>\n",
       "      <td>421</td>\n",
       "      <td>22-10-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Bleacher Report</td>\n",
       "      <td>https://bleacherreport.com/articles/10054125-p...</td>\n",
       "      <td>Patrick Peterson: Critical Emails from Cardina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>90136714</td>\n",
       "      <td>1119</td>\n",
       "      <td>22-10-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Buffalo News</td>\n",
       "      <td>https://buffalonews.com/sports/bills/plays-tha...</td>\n",
       "      <td>Plays that shaped the game: Josh Allen's spect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87596 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID words      date country             source  \\\n",
       "0      89996010  1177  22-10-01      US  The Baltimore Sun   \n",
       "1      89996011   923  22-10-01      US                ABC   \n",
       "2      89996012   981  22-10-01      US   Associated Press   \n",
       "3      89996013   534  22-10-01      US   Associated Press   \n",
       "4      89996014   602  22-10-01      US   Associated Press   \n",
       "...         ...   ...       ...     ...                ...   \n",
       "87591  90136835   430  22-10-31      US   Business Insider   \n",
       "87592  90136708   274  22-10-31      US                ABC   \n",
       "87593  90136710   260  22-10-31      US                ABC   \n",
       "87594  90136713   421  22-10-31      US    Bleacher Report   \n",
       "87595  90136714  1119  22-10-31      US       Buffalo News   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.baltimoresun.com/education/bs-md-j...   \n",
       "1      https://abcnews.go.com/Sports/wireStory/corum-...   \n",
       "2      https://apnews.com/2098f5cb7ebb4fcd42bfccd6f5a...   \n",
       "3      https://apnews.com/49ca6d17cf1c8e0a8eae8f33de5...   \n",
       "4      https://apnews.com/9186f70b3fb426c70d4f8948296...   \n",
       "...                                                  ...   \n",
       "87591  https://markets.businessinsider.com/news/stock...   \n",
       "87592  https://abcnews.go.com/Business/wireStory/week...   \n",
       "87593  https://abcnews.go.com/US/dead-chattanooga-sho...   \n",
       "87594  https://bleacherreport.com/articles/10054125-p...   \n",
       "87595  https://buffalonews.com/sports/bills/plays-tha...   \n",
       "\n",
       "                                                headline  \n",
       "0      Minority students make up a small fraction of ...  \n",
       "1      Corum, McCarthy lead No. 4 Michigan past Iowa,...  \n",
       "2      Raleigh's walk-off homer ends Mariners' long p...  \n",
       "3      Max Baer, Pennsylvania Supreme Court's chief j...  \n",
       "4      US women's basketball dominates on internation...  \n",
       "...                                                  ...  \n",
       "87591  Full Truck Alliance Co. Ltd. Announces Gross T...  \n",
       "87592  This Week: Fed meeting, Starbucks earns, jobs ...  \n",
       "87593         2 dead in Chattanooga shooting, police say  \n",
       "87594  Patrick Peterson: Critical Emails from Cardina...  \n",
       "87595  Plays that shaped the game: Josh Allen's spect...  \n",
       "\n",
       "[87596 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import csv  # Required for quoting constants like QUOTE_NONE\n",
    "\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-22-10.txt\"\n",
    "\n",
    "# Initialize lists to hold valid and invalid rows\n",
    "valid_rows = []\n",
    "invalid_rows = []\n",
    "\n",
    "# Set maximum row limit\n",
    "max_rows_to_process = 313875\n",
    "\n",
    "try:\n",
    "    # Read the file without chunks, handle quotes and force data types\n",
    "    data = pd.read_csv(\n",
    "        file_path,\n",
    "        delimiter='\\t',\n",
    "        encoding='ISO-8859-1',\n",
    "        on_bad_lines='warn',\n",
    "        nrows=max_rows_to_process,\n",
    "        quoting=csv.QUOTE_NONE,  # Treat all text literally, do not treat quotes as special\n",
    "        escapechar='\\\\',  # Escape special characters if needed\n",
    "        dtype=str,  # Force all columns to be read as strings\n",
    "        low_memory=False  # Avoid mixed-type warnings\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values with empty strings to avoid issues with non-iterable types\n",
    "    data.fillna('', inplace=True)\n",
    "\n",
    "    # Assign column names (adjust based on actual structure if needed)\n",
    "    data.columns = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "\n",
    "    # Decode HTML entities in text fields\n",
    "    data[\"headline\"] = data[\"headline\"].apply(html.unescape)\n",
    "    data[\"url\"] = data[\"url\"].apply(html.unescape)\n",
    "\n",
    "    # Filter rows into valid and invalid lists\n",
    "    for index, row in data.iterrows():\n",
    "        if all(row.notnull()) and len(row) == 7:  # Ensure all fields are non-null and correctly structured\n",
    "            valid_rows.append(row)\n",
    "        else:\n",
    "            invalid_rows.append(row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the file: {e}\")\n",
    "\n",
    "# Create a DataFrame from the valid rows\n",
    "sources_22_10 = pd.DataFrame(valid_rows, columns=[\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"])\n",
    "\n",
    "# Display invalid rows for debugging, if needed\n",
    "print(f\"Invalid rows: {len(invalid_rows)}\")\n",
    "for row in invalid_rows[:5]:  # Display a sample of invalid rows\n",
    "    print(row)\n",
    "\n",
    "# Display the final DataFrame\n",
    "sources_22_10\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_22_10 = sources_22_10[sources_22_10[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_22_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbc132-c44b-49e6-a37e-804c91e3b760",
   "metadata": {},
   "source": [
    "### Issue might be because of an error with this line \" 90045730\t260\t22-10-11\t??\tgolfweek.usatoday\thttps://golfweek.usatoday.com/lists/affordable-golf-bags-cart-stand-carry-travel/\tBest affordable golf bags: Carry your clubs for less than $200 \". But the rest of the sources have ?? as country, so I doubt they would be included anyway. So we'll just use this for for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50fddfe7-53a5-4a52-8770-d6e15b6f6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/sus_sources/sources_22_10_susnomore.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sources_22_10.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e03a35-e37b-4197-a15f-10a7edd381c4",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70934e05-b071-4465-83ea-9a52fb29637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         textID                                               body\n",
      "0      89996000  Orlando Mayorquin, USA TODAY\\nSeptember 30, 20...\n",
      "1      89996001  There was no way NBA executives could've predi...\n",
      "2      89996002  Eugene Quaynor, a Ghanan graduate student who ...\n",
      "3      89996003  The Baltimore Ravens signed defensive tackle M...\n",
      "4      89996005  The Memphis Grizzlies play against the Milwauk...\n",
      "...         ...                                                ...\n",
      "89219  94532880  CHARLESTON, W.Va. ( WV News ) -- The COVID dea...\n",
      "89220  94532883  CLARKSBURG, W.Va. ( WV News ) -- Nearly 1,800 ...\n",
      "89221  94532884  SOUTH CHARLESTON, W.Va. ( WV News ) -- Hunting...\n",
      "89222  94532886  CLARKSBURG, W.Va. ( WV News ) -- Thanksgiving ...\n",
      "89223  94532888  With West Virginians and all of the nation dea...\n",
      "\n",
      "[89224 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-10/22-10-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-10/22-10-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-10/22-10-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-10/22-10-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-10/22-10-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_22_10 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(text_22_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f402c0-89b3-47db-90bb-6c06b249e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  sources   texts\n",
      "0  21-08   150012  154411\n",
      "1  22-10    87596   89224\n"
     ]
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe for text_22_10 and sources_22_10\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\", \"22-10\"],  # Column for the months\n",
    "    \"sources\": [len(sources_21_08), len(sources_22_10)],  # Number of rows in sources dataframes\n",
    "    \"texts\": [len(text_21_08), len(text_22_10)]  # Number of rows in text dataframes\n",
    "})\n",
    "\n",
    "# Display the sus_months dataframe\n",
    "print(sus_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64a9fb-fa4e-4fda-85ea-21fdbc066d61",
   "metadata": {},
   "source": [
    "## 22-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b1f11-ecad-4d90-868e-99fa698a0bed",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f039cd5-1557-4499-a2f6-1d3a1c320df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed line 120781: Tettenhall | 15 hours ago\n",
      "...\n",
      "Malformed line 126650: \n",
      "...\n",
      "Malformed line 126651: West Bromwich | 7 hours ago\n",
      "...\n",
      "Malformed line 134932: South Shropshire | 10 hours ago\n",
      "...\n",
      "Malformed line 134946: Toby Neal | 15 hours ago\n",
      "...\n",
      "Malformed line 143059: \n",
      "...\n",
      "Malformed line 143060:  Newtown | 6 hours ago\n",
      "...\n",
      "Malformed line 146799: Wolverhampton | 7 hours ago\n",
      "...\n",
      "Malformed line 155090: Wolverhampton | 5 hours ago\n",
      "...\n",
      "Malformed line 157275: \n",
      "...\n",
      "Malformed line 157276: \n",
      "...\n",
      "Malformed line 157277: Wolverhampton | 12 hours ago\n",
      "...\n",
      "Malformed line 157294: Telford | 8 hours ago\n",
      "...\n",
      "Malformed line 157297: they close gap at the topCricket | 11 hours ago\n",
      "...\n",
      "Malformed line 157303: \n",
      "...\n",
      "Malformed line 161662: Football | 15 hours ago\n",
      "...\n",
      "Malformed line 163387: Toby Neal | 15 hours ago\n",
      "...\n",
      "Malformed line 166914: Staffordshire | 8 hours ago\n",
      "...\n",
      "Malformed line 168887: Walsall FC | 12 hours ago\n",
      "...\n",
      "Malformed line 168893: Business | 14 hours ago\n",
      "...\n",
      "Malformed line 232675: ... \n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89217290</td>\n",
       "      <td>634</td>\n",
       "      <td>22-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>HoopsHype</td>\n",
       "      <td>https://hoopshype.com/2022/04/16/x-rays-negati...</td>\n",
       "      <td>X-rays negative for Scottie Barnes, MRI awaits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89217291</td>\n",
       "      <td>929</td>\n",
       "      <td>22-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>https://investorplace.com/2022/05/3-undervalue...</td>\n",
       "      <td>3 Undervalued Stocks to Buy in May 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89217295</td>\n",
       "      <td>4336</td>\n",
       "      <td>22-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/titans-day-3-picks-said...</td>\n",
       "      <td>What Titans' Day 3 picks said after being drafted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89217296</td>\n",
       "      <td>1971</td>\n",
       "      <td>22-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://seekingalpha.com/article/4505613-disne...</td>\n",
       "      <td>Analysis: Disney Could Turn Around, But Invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89217297</td>\n",
       "      <td>1456</td>\n",
       "      <td>22-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo! Sports</td>\n",
       "      <td>https://sports.yahoo.com/cavalier-johnson-beco...</td>\n",
       "      <td>Cavalier Johnson becomes first African America...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85295</th>\n",
       "      <td>91183907</td>\n",
       "      <td>1066</td>\n",
       "      <td>22-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://nola.com/news/crime_police/article_76e...</td>\n",
       "      <td>Read the full story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85296</th>\n",
       "      <td>91183908</td>\n",
       "      <td>807</td>\n",
       "      <td>22-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://nola.com/entertainment_life/article_3c...</td>\n",
       "      <td>Read the full story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85297</th>\n",
       "      <td>91183909</td>\n",
       "      <td>289</td>\n",
       "      <td>22-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://nola.com/news/crime_police/article_1b7...</td>\n",
       "      <td>Read the full story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85298</th>\n",
       "      <td>91183910</td>\n",
       "      <td>193</td>\n",
       "      <td>22-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://nola.com/news/northshore/article_c836b...</td>\n",
       "      <td>Read the full story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85299</th>\n",
       "      <td>91183911</td>\n",
       "      <td>185</td>\n",
       "      <td>22-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://nola.com/news/article_c71646ba-dc88-11...</td>\n",
       "      <td>Read the full story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID words      date country            source  \\\n",
       "0      89217290   634  22-05-01      US         HoopsHype   \n",
       "1      89217291   929  22-05-01      US  Business Insider   \n",
       "2      89217295  4336  22-05-01      US        YAHOO!News   \n",
       "3      89217296  1971  22-05-01      US     Seeking Alpha   \n",
       "4      89217297  1456  22-05-01      US     Yahoo! Sports   \n",
       "...         ...   ...       ...     ...               ...   \n",
       "85295  91183907  1066  22-05-31      US          nola.com   \n",
       "85296  91183908   807  22-05-31      US          nola.com   \n",
       "85297  91183909   289  22-05-31      US          nola.com   \n",
       "85298  91183910   193  22-05-31      US          nola.com   \n",
       "85299  91183911   185  22-05-31      US          nola.com   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://hoopshype.com/2022/04/16/x-rays-negati...   \n",
       "1      https://investorplace.com/2022/05/3-undervalue...   \n",
       "2      https://news.yahoo.com/titans-day-3-picks-said...   \n",
       "3      https://seekingalpha.com/article/4505613-disne...   \n",
       "4      https://sports.yahoo.com/cavalier-johnson-beco...   \n",
       "...                                                  ...   \n",
       "85295  https://nola.com/news/crime_police/article_76e...   \n",
       "85296  https://nola.com/entertainment_life/article_3c...   \n",
       "85297  https://nola.com/news/crime_police/article_1b7...   \n",
       "85298  https://nola.com/news/northshore/article_c836b...   \n",
       "85299  https://nola.com/news/article_c71646ba-dc88-11...   \n",
       "\n",
       "                                                headline  \n",
       "0      X-rays negative for Scottie Barnes, MRI awaits...  \n",
       "1                3 Undervalued Stocks to Buy in May 2022  \n",
       "2      What Titans' Day 3 picks said after being drafted  \n",
       "3      Analysis: Disney Could Turn Around, But Invest...  \n",
       "4      Cavalier Johnson becomes first African America...  \n",
       "...                                                  ...  \n",
       "85295                                Read the full story  \n",
       "85296                                Read the full story  \n",
       "85297                                Read the full story  \n",
       "85298                                Read the full story  \n",
       "85299                                Read the full story  \n",
       "\n",
       "[85300 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-22-05.txt\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "rows = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            # Split the line using tab as the delimiter\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            \n",
    "            # Check if the line has the correct number of fields\n",
    "            if len(fields) == 7:\n",
    "                rows.append(fields)\n",
    "            else:\n",
    "                print(f\"Malformed line {line_number}: {line[:100]}...\")  # Log the malformed line (first 100 chars)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the file line-by-line: {e}\")\n",
    "\n",
    "# Convert to a DataFrame\n",
    "column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "sources_22_05 = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "# Display the DataFrame\n",
    "sources_22_05\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_22_05 = sources_22_05[sources_22_05[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_22_05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "408308aa-b4e7-43bb-a5e7-519aa9d128db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/sus_sources/sources_22_05_susnomore.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sources_22_05.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa4528-7e99-4f15-8368-6be17baab874",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4916bfbb-69c8-4766-bf13-4621270b95a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89217300</td>\n",
       "      <td>The Quincy Lady Orioles took runner-up honors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89217301</td>\n",
       "      <td>The lawsuit against Family Dollar was filed on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89217302</td>\n",
       "      <td>ALLIANCE -- The city of Alliance and OhioMeans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89217304</td>\n",
       "      <td>\" How did the Sure Power herbicide you referen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89217305</td>\n",
       "      <td>DJs From Mars, musicians from Italy, pose at C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88875</th>\n",
       "      <td>91183895</td>\n",
       "      <td>The Clarksburg Water Board, from left, member ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88876</th>\n",
       "      <td>91183896</td>\n",
       "      <td>GRAFTON, W.Va. ( WV News ) -- The city of Graf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88877</th>\n",
       "      <td>91183897</td>\n",
       "      <td>CLARKSBURG, W.Va. ( WV News ) -- When the Harr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88878</th>\n",
       "      <td>91183898</td>\n",
       "      <td>CLARKSBURG, W.VA. -- Ryan and Sarah Rutt, owne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88879</th>\n",
       "      <td>91183899</td>\n",
       "      <td>CLARKSBURG, W.Va. ( WV News ) -- As Class AA N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID                                               body\n",
       "0      89217300  The Quincy Lady Orioles took runner-up honors ...\n",
       "1      89217301  The lawsuit against Family Dollar was filed on...\n",
       "2      89217302  ALLIANCE -- The city of Alliance and OhioMeans...\n",
       "3      89217304  \" How did the Sure Power herbicide you referen...\n",
       "4      89217305  DJs From Mars, musicians from Italy, pose at C...\n",
       "...         ...                                                ...\n",
       "88875  91183895  The Clarksburg Water Board, from left, member ...\n",
       "88876  91183896  GRAFTON, W.Va. ( WV News ) -- The city of Graf...\n",
       "88877  91183897  CLARKSBURG, W.Va. ( WV News ) -- When the Harr...\n",
       "88878  91183898  CLARKSBURG, W.VA. -- Ryan and Sarah Rutt, owne...\n",
       "88879  91183899  CLARKSBURG, W.Va. ( WV News ) -- As Class AA N...\n",
       "\n",
       "[88880 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-05/22-05-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-05/22-05-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-05/22-05-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-05/22-05-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-05/22-05-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_22_05 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "text_22_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39fb14a2-7b86-4663-8e5c-edc872aeb7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  sources   texts\n",
      "0  21-08   150012  154411\n",
      "1  22-10    87596   89224\n",
      "2  22-05    85300   88880\n"
     ]
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe for text_22_10 and sources_22_10\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\", \"22-10\", \"22-05\"],  # Column for the months\n",
    "    \"sources\": [len(sources_21_08), len(sources_22_10), len(sources_22_05)],  # Number of rows in sources dataframes\n",
    "    \"texts\": [len(text_21_08), len(text_22_10), len(text_22_05)]  # Number of rows in text dataframes\n",
    "})\n",
    "\n",
    "# Display the sus_months dataframe\n",
    "print(sus_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236b482-8c3a-48d1-b2fc-96796aabc595",
   "metadata": {},
   "source": [
    "## 24-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e37e25-73a1-400a-9820-0763252469ec",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4dba3a9-b053-49b2-8a89-8626516c9016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200443171</td>\n",
       "      <td>500</td>\n",
       "      <td>24-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>gizmodo.com</td>\n",
       "      <td>https://gizmodo.com/dave-busters-bet-wagers-be...</td>\n",
       "      <td>Dave &amp; Buster's Adding Bets to Its App as Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200443172</td>\n",
       "      <td>815</td>\n",
       "      <td>24-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>gizmodo.com</td>\n",
       "      <td>https://gizmodo.com/how-to-track-your-medicati...</td>\n",
       "      <td>How to Track Your Medications with iOS and And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200443173</td>\n",
       "      <td>366</td>\n",
       "      <td>24-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>markets.businessinsider.com</td>\n",
       "      <td>https://markets.businessinsider.com/news/curre...</td>\n",
       "      <td>Bitcoin will drop 13% to $50,000 after falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200443174</td>\n",
       "      <td>912</td>\n",
       "      <td>24-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>markets.businessinsider.com</td>\n",
       "      <td>https://markets.businessinsider.com/news/stock...</td>\n",
       "      <td>Leading the Way in Broaching Machinery: Taizho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200443175</td>\n",
       "      <td>261</td>\n",
       "      <td>24-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>markets.businessinsider.com</td>\n",
       "      <td>https://markets.businessinsider.com/news/stock...</td>\n",
       "      <td>TransMedics Stock Skyrockets, Analysts Call It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58732</th>\n",
       "      <td>108663272</td>\n",
       "      <td>418</td>\n",
       "      <td>24-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcchicago.com</td>\n",
       "      <td>https://www.nbcchicago.com/news/local/illinois...</td>\n",
       "      <td>Illinois teen drivers need an exclusive DMV ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58733</th>\n",
       "      <td>108663275</td>\n",
       "      <td>272</td>\n",
       "      <td>24-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcchicago.com</td>\n",
       "      <td>https://www.nbcchicago.com/news/business/money...</td>\n",
       "      <td>Mega backdoor Roth conversions can be a `no br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58734</th>\n",
       "      <td>108663277</td>\n",
       "      <td>545</td>\n",
       "      <td>24-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcchicago.com</td>\n",
       "      <td>https://www.nbcchicago.com/news/national-inter...</td>\n",
       "      <td>Democratic Sen. Joe Manchin of West Virginia r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58735</th>\n",
       "      <td>108663278</td>\n",
       "      <td>248</td>\n",
       "      <td>24-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcchicago.com</td>\n",
       "      <td>https://www.nbcchicago.com/news/local/recall-a...</td>\n",
       "      <td>Tesla recalling more than 125,000 vehicles to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58736</th>\n",
       "      <td>108662051</td>\n",
       "      <td>473</td>\n",
       "      <td>24-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://www.food24.com/golden-spur-reopens/?ut...</td>\n",
       "      <td>Golden Spur reopens: A nostalgic journey into...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58737 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  words      date country                       source  \\\n",
       "0      200443171    500  24-05-01      US                  gizmodo.com   \n",
       "1      200443172    815  24-05-01      US                  gizmodo.com   \n",
       "2      200443173    366  24-05-01      US  markets.businessinsider.com   \n",
       "3      200443174    912  24-05-01      US  markets.businessinsider.com   \n",
       "4      200443175    261  24-05-01      US  markets.businessinsider.com   \n",
       "...          ...    ...       ...     ...                          ...   \n",
       "58732  108663272    418  24-05-31      US               nbcchicago.com   \n",
       "58733  108663275    272  24-05-31      US               nbcchicago.com   \n",
       "58734  108663277    545  24-05-31      US               nbcchicago.com   \n",
       "58735  108663278    248  24-05-31      US               nbcchicago.com   \n",
       "58736  108662051    473  24-05-31      US                     nola.com   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://gizmodo.com/dave-busters-bet-wagers-be...   \n",
       "1      https://gizmodo.com/how-to-track-your-medicati...   \n",
       "2      https://markets.businessinsider.com/news/curre...   \n",
       "3      https://markets.businessinsider.com/news/stock...   \n",
       "4      https://markets.businessinsider.com/news/stock...   \n",
       "...                                                  ...   \n",
       "58732  https://www.nbcchicago.com/news/local/illinois...   \n",
       "58733  https://www.nbcchicago.com/news/business/money...   \n",
       "58734  https://www.nbcchicago.com/news/national-inter...   \n",
       "58735  https://www.nbcchicago.com/news/local/recall-a...   \n",
       "58736  https://www.food24.com/golden-spur-reopens/?ut...   \n",
       "\n",
       "                                                headline  \n",
       "0      Dave & Buster's Adding Bets to Its App as Amer...  \n",
       "1      How to Track Your Medications with iOS and And...  \n",
       "2      Bitcoin will drop 13% to $50,000 after falling...  \n",
       "3      Leading the Way in Broaching Machinery: Taizho...  \n",
       "4      TransMedics Stock Skyrockets, Analysts Call It...  \n",
       "...                                                  ...  \n",
       "58732  Illinois teen drivers need an exclusive DMV ap...  \n",
       "58733  Mega backdoor Roth conversions can be a `no br...  \n",
       "58734  Democratic Sen. Joe Manchin of West Virginia r...  \n",
       "58735  Tesla recalling more than 125,000 vehicles to ...  \n",
       "58736   Golden Spur reopens: A nostalgic journey into...  \n",
       "\n",
       "[58737 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-24-05.txt\"  # Replace 'your_file_name.txt' with the actual file name\n",
    "\n",
    "# check if the path is a valid file and ends with '.txt'\n",
    "if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "    try:\n",
    "        # read the file into a dataframe, skipping bad lines\n",
    "        sources_24_05 = pd.read_csv(\n",
    "            file_path, \n",
    "            delimiter='\\t', \n",
    "            encoding='ISO-8859-1',\n",
    "            on_bad_lines='skip'  # Skip lines with too many or too few fields\n",
    "        )\n",
    "        \n",
    "        # define and assign column names\n",
    "        column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "        sources_24_05.columns = column_names\n",
    "        \n",
    "        # display the dataframe\n",
    "        sources_24_05\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError in file: {file_path}\")\n",
    "        print(e)\n",
    "        # log the problematic file\n",
    "        with open(\"/work/LauraSørineVoldgaard#8191/problematic_files.log\", \"a\") as log_file:\n",
    "            log_file.write(f\"ParserError in file: {file_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error in file: {file_path}. Error: {e}\")\n",
    "else:\n",
    "    print(f\"The specified file does not exist or is not a '.txt' file: {file_path}\")\n",
    "\n",
    "\n",
    "sources_24_05\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_24_05 = sources_24_05[sources_24_05[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_24_05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff0b48-99ec-4399-b8eb-3732897fa7c0",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97f9bfa3-59d7-49a4-9689-433b9c21bdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107886812</td>\n",
       "      <td>Price chart patterns suggest that the uptrend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107886818</td>\n",
       "      <td>Starbucks shares plummeted Tuesday evening by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107886819</td>\n",
       "      <td>Amazon reported a strong first quarter after t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107887000</td>\n",
       "      <td>\" I might make a joke about being a cougar and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107887001</td>\n",
       "      <td>Artificial Intelligence has designed what the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59590</th>\n",
       "      <td>200504588</td>\n",
       "      <td>A New York jury on Thursday evening found Dona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59591</th>\n",
       "      <td>200504589</td>\n",
       "      <td>4 minute read\\nTIME\\nMay 30, 1960 12:00 AM GMT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59592</th>\n",
       "      <td>200504591</td>\n",
       "      <td>Angel Studios is planning to appeal an arbitra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59593</th>\n",
       "      <td>200504597</td>\n",
       "      <td>Macomb County Sheriff Anthony Wickersham said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59594</th>\n",
       "      <td>200504599</td>\n",
       "      <td>A gasp surged through Courtroom 1530 of the Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               body\n",
       "0      107886812  Price chart patterns suggest that the uptrend ...\n",
       "1      107886818  Starbucks shares plummeted Tuesday evening by ...\n",
       "2      107886819  Amazon reported a strong first quarter after t...\n",
       "3      107887000  \" I might make a joke about being a cougar and...\n",
       "4      107887001  Artificial Intelligence has designed what the ...\n",
       "...          ...                                                ...\n",
       "59590  200504588  A New York jury on Thursday evening found Dona...\n",
       "59591  200504589  4 minute read\\nTIME\\nMay 30, 1960 12:00 AM GMT...\n",
       "59592  200504591  Angel Studios is planning to appeal an arbitra...\n",
       "59593  200504597  Macomb County Sheriff Anthony Wickersham said ...\n",
       "59594  200504599  A gasp surged through Courtroom 1530 of the Ma...\n",
       "\n",
       "[59595 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-05/24-05-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-05/24-05-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-05/24-05-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-05/24-05-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-05/24-05-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_24_05 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "text_24_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4312656-50a1-428f-bb6b-a15a03755f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  sources   texts\n",
      "0  21-08   150012  154411\n",
      "1  22-10    87596   89224\n",
      "2  22-05    85300   88880\n",
      "3  24-05    58737   59595\n"
     ]
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe for text_22_10 and sources_22_10\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\", \"22-10\", \"22-05\", \"24-05\"],  # Column for the months\n",
    "    \"sources\": [len(sources_21_08), len(sources_22_10), len(sources_22_05), len(sources_24_05)],  # Number of rows in sources dataframes\n",
    "    \"texts\": [len(text_21_08), len(text_22_10), len(text_22_05), len(text_24_05)]  # Number of rows in text dataframes\n",
    "})\n",
    "\n",
    "# Display the sus_months dataframe\n",
    "print(sus_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54f8e0-f710-4fb1-bc57-696958b0f0d8",
   "metadata": {},
   "source": [
    "## 22-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1addc627-b845-4265-bbf6-13b4a2c7c837",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75b019cf-caff-4de0-95ac-9b92d5239199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_806/327802139.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sources_22_09 = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93233590</td>\n",
       "      <td>5839.0</td>\n",
       "      <td>22-09-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/interactive/2022/09/01...</td>\n",
       "      <td>Focus GroupThese 12 Teachers Have a Word or Tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93233624</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>22-09-01</td>\n",
       "      <td>US</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>https://www.washingtonpost.com/health/2022/09/...</td>\n",
       "      <td>BREAKING NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93233626</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>22-09-01</td>\n",
       "      <td>US</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>https://www.washingtonpost.com/science/2022/09...</td>\n",
       "      <td>In summer of viruses, new disease outbreaks be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93233627</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>22-09-01</td>\n",
       "      <td>US</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>https://www.washingtonpost.com/investigations/...</td>\n",
       "      <td>Ginni Thomas pressed Wisconsin lawmakers to ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93233628</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>22-09-01</td>\n",
       "      <td>US</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>https://www.washingtonpost.com/politics/2022/0...</td>\n",
       "      <td>POST POLITICS NOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108639</th>\n",
       "      <td>93877604</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>22-09-30</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/bluegoldnews/huggins-west-v...</td>\n",
       "      <td>Huggins: West Virginia basketball schedule ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108640</th>\n",
       "      <td>93877606</td>\n",
       "      <td>419.0</td>\n",
       "      <td>22-09-30</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/news/wvnews/wvu-fraternity-...</td>\n",
       "      <td>WVU fraternity cleared of hazing allegation, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108641</th>\n",
       "      <td>93877608</td>\n",
       "      <td>729.0</td>\n",
       "      <td>22-09-30</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/bluegoldnews/wvu-will-learn...</td>\n",
       "      <td>WVU will learn what it's made of against Robin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108642</th>\n",
       "      <td>93877612</td>\n",
       "      <td>160.0</td>\n",
       "      <td>22-09-30</td>\n",
       "      <td>US</td>\n",
       "      <td>pbs.org</td>\n",
       "      <td>https://pbs.org/video/brooks-and-tumulty-on-pu...</td>\n",
       "      <td>Brooks and Tumulty on Putin&amp;#x27;s war and Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108643</th>\n",
       "      <td>93877613</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>22-09-30</td>\n",
       "      <td>US</td>\n",
       "      <td>nola.com</td>\n",
       "      <td>https://nola.com/entertainment_life/article_12...</td>\n",
       "      <td>Read the full story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID   words      date country              source  \\\n",
       "0       93233590  5839.0  22-09-01      US         nytimes.com   \n",
       "1       93233624  1705.0  22-09-01      US  washingtonpost.com   \n",
       "2       93233626  1981.0  22-09-01      US  washingtonpost.com   \n",
       "3       93233627  1327.0  22-09-01      US  washingtonpost.com   \n",
       "4       93233628  1601.0  22-09-01      US  washingtonpost.com   \n",
       "...          ...     ...       ...     ...                 ...   \n",
       "108639  93877604  1277.0  22-09-30      US          wvnews.com   \n",
       "108640  93877606   419.0  22-09-30      US          wvnews.com   \n",
       "108641  93877608   729.0  22-09-30      US          wvnews.com   \n",
       "108642  93877612   160.0  22-09-30      US             pbs.org   \n",
       "108643  93877613  1594.0  22-09-30      US            nola.com   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.nytimes.com/interactive/2022/09/01...   \n",
       "1       https://www.washingtonpost.com/health/2022/09/...   \n",
       "2       https://www.washingtonpost.com/science/2022/09...   \n",
       "3       https://www.washingtonpost.com/investigations/...   \n",
       "4       https://www.washingtonpost.com/politics/2022/0...   \n",
       "...                                                   ...   \n",
       "108639  https://wvnews.com/bluegoldnews/huggins-west-v...   \n",
       "108640  https://wvnews.com/news/wvnews/wvu-fraternity-...   \n",
       "108641  https://wvnews.com/bluegoldnews/wvu-will-learn...   \n",
       "108642  https://pbs.org/video/brooks-and-tumulty-on-pu...   \n",
       "108643  https://nola.com/entertainment_life/article_12...   \n",
       "\n",
       "                                                 headline  \n",
       "0       Focus GroupThese 12 Teachers Have a Word or Tw...  \n",
       "1                                           BREAKING NEWS  \n",
       "2       In summer of viruses, new disease outbreaks be...  \n",
       "3       Ginni Thomas pressed Wisconsin lawmakers to ov...  \n",
       "4                                       POST POLITICS NOW  \n",
       "...                                                   ...  \n",
       "108639  Huggins: West Virginia basketball schedule ful...  \n",
       "108640  WVU fraternity cleared of hazing allegation, s...  \n",
       "108641  WVU will learn what it's made of against Robin...  \n",
       "108642  Brooks and Tumulty on Putin&#x27;s war and Rep...  \n",
       "108643                                Read the full story  \n",
       "\n",
       "[108644 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-22-09.txt\"  # Replace 'your_file_name.txt' with the actual file name\n",
    "\n",
    "# check if the path is a valid file and ends with '.txt'\n",
    "if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "    try:\n",
    "        # read the file into a dataframe, skipping bad lines\n",
    "        sources_22_09 = pd.read_csv(\n",
    "            file_path, \n",
    "            delimiter='\\t', \n",
    "            encoding='ISO-8859-1',\n",
    "            on_bad_lines='skip'  # Skip lines with too many or too few fields\n",
    "        )\n",
    "        \n",
    "        # define and assign column names\n",
    "        column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "        sources_22_09.columns = column_names\n",
    "        \n",
    "        # display the dataframe\n",
    "        sources_22_09\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError in file: {file_path}\")\n",
    "        print(e)\n",
    "        # log the problematic file\n",
    "        with open(\"/work/LauraSørineVoldgaard#8191/problematic_files.log\", \"a\") as log_file:\n",
    "            log_file.write(f\"ParserError in file: {file_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error in file: {file_path}. Error: {e}\")\n",
    "else:\n",
    "    print(f\"The specified file does not exist or is not a '.txt' file: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_22_09 = sources_22_09[sources_22_09[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_22_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40706bd1-972e-4c40-8c47-17ead5b40a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/sus_sources/sources_22_09_susnomore.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sources_22_09.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc186d59-d7a1-4ce0-a8d0-ae8369f1b19f",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9fc5184-04a2-430a-a48c-da4f30609657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89863200</td>\n",
       "      <td>Italian bonds led losses in the region on Thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89863202</td>\n",
       "      <td>After the' Transparent' actress landed a role ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89863203</td>\n",
       "      <td>Two of the most anticipated Japanese films sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89863204</td>\n",
       "      <td>Notably, Amazon boasts of five successful busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89863205</td>\n",
       "      <td>HOUSTON, Sept. 1, 2022 /PRNewswire/ -- McDermo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114871</th>\n",
       "      <td>93877580</td>\n",
       "      <td>His employment began in 1981 as a groundskeepe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114872</th>\n",
       "      <td>93877585</td>\n",
       "      <td>MORGANTOWN ( WV News ) -- An unexpected visito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114873</th>\n",
       "      <td>93877586</td>\n",
       "      <td>CHARLESTON, W.Va. ( WV News ) -- Ten more COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114874</th>\n",
       "      <td>93877587</td>\n",
       "      <td>MORGANTOWN, W.Va. ( WV News ) -- CONSOL Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114875</th>\n",
       "      <td>93877589</td>\n",
       "      <td>CLARKSBURG, W.Va. ( WV News ) -- A school bus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               body\n",
       "0       89863200  Italian bonds led losses in the region on Thur...\n",
       "1       89863202  After the' Transparent' actress landed a role ...\n",
       "2       89863203  Two of the most anticipated Japanese films sho...\n",
       "3       89863204  Notably, Amazon boasts of five successful busi...\n",
       "4       89863205  HOUSTON, Sept. 1, 2022 /PRNewswire/ -- McDermo...\n",
       "...          ...                                                ...\n",
       "114871  93877580  His employment began in 1981 as a groundskeepe...\n",
       "114872  93877585  MORGANTOWN ( WV News ) -- An unexpected visito...\n",
       "114873  93877586  CHARLESTON, W.Va. ( WV News ) -- Ten more COVI...\n",
       "114874  93877587  MORGANTOWN, W.Va. ( WV News ) -- CONSOL Energy...\n",
       "114875  93877589  CLARKSBURG, W.Va. ( WV News ) -- A school bus ...\n",
       "\n",
       "[114876 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-09/22-09-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-09/22-09-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-09/22-09-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-09/22-09-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-09/22-09-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_22_09 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "text_22_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18529293-0a9d-4193-b6d7-e0abfd9cc852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  sources   texts\n",
      "0  21-08   150012  154411\n",
      "1  22-10    87596   89224\n",
      "2  22-05    85300   88880\n",
      "3  24-05    58737   59595\n",
      "4  22-09   108644  114876\n"
     ]
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe for text_22_10 and sources_22_10\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\", \"22-10\", \"22-05\", \"24-05\", \"22-09\"],  # Column for the months\n",
    "    \"sources\": [len(sources_21_08), len(sources_22_10), len(sources_22_05), len(sources_24_05), len(sources_22_09)],  # Number of rows in sources dataframes\n",
    "    \"texts\": [len(text_21_08), len(text_22_10), len(text_22_05), len(text_24_05), len(text_22_09)]  # Number of rows in text dataframes\n",
    "})\n",
    "\n",
    "# Display the sus_months dataframe\n",
    "print(sus_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d575438-3df3-49ce-9c24-630bf2c81d12",
   "metadata": {},
   "source": [
    "## 22-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e7d5a-6fa8-4162-b0b3-a578b1d605ba",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82c53b2b-72d6-4c4a-adce-5c63633ff75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_806/3081515372.py:8: DtypeWarning: Columns (0,2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sources_22_06 = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89403424</td>\n",
       "      <td>727.0</td>\n",
       "      <td>22-06-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahoo.com/lifestyle/lego-star-wars...</td>\n",
       "      <td>'LEGO Star Wars: The Skywalker Saga' is loaded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89403429</td>\n",
       "      <td>269.0</td>\n",
       "      <td>22-06-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Axios</td>\n",
       "      <td>https://www.axios.com/2022/06/01/fbi-iran-hack...</td>\n",
       "      <td>FBI head: Agency blocked Iranian cyberattack o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89403430</td>\n",
       "      <td>169.0</td>\n",
       "      <td>22-06-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Axios</td>\n",
       "      <td>https://www.axios.com/local/twin-cities/2022/0...</td>\n",
       "      <td>Jesse Ventura turns to Substack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89403434</td>\n",
       "      <td>992.0</td>\n",
       "      <td>22-06-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Boston.com</td>\n",
       "      <td>https://www.boston.com/community/music-club/me...</td>\n",
       "      <td>Meet solo artist Adi Sun, one the top singer-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89403435</td>\n",
       "      <td>350.0</td>\n",
       "      <td>22-06-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>https://www.businessinsider.com/pamplona-priva...</td>\n",
       "      <td>A private equity company wants to cut ties wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80233</th>\n",
       "      <td>89566655</td>\n",
       "      <td>3298.0</td>\n",
       "      <td>22-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahoo.com/lifestyle/11-men-share-e...</td>\n",
       "      <td>11 men share their experiences of abortion aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80234</th>\n",
       "      <td>89566656</td>\n",
       "      <td>614.0</td>\n",
       "      <td>22-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahoo.com/lifestyle/yes-ice-cream-...</td>\n",
       "      <td>Yes, You Can Have Ice Cream Delivered Straight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80235</th>\n",
       "      <td>89566657</td>\n",
       "      <td>287.0</td>\n",
       "      <td>22-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahoo.com/news/football-rumours-bo...</td>\n",
       "      <td>Borussia Dortmund set Jude Bellingham's price ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80236</th>\n",
       "      <td>89566570</td>\n",
       "      <td>384.0</td>\n",
       "      <td>22-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>https://thehill.com/changing-america/enrichmen...</td>\n",
       "      <td>New Jersey is losing residents to states like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80237</th>\n",
       "      <td>89566572</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>22-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>https://thehill.com/homenews/campaign/3541597-...</td>\n",
       "      <td>Five takeaways from the finalized House maps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80238 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID   words      date country            source  \\\n",
       "0      89403424   727.0  22-06-01      US             Yahoo   \n",
       "1      89403429   269.0  22-06-01      US             Axios   \n",
       "2      89403430   169.0  22-06-01      US             Axios   \n",
       "3      89403434   992.0  22-06-01      US        Boston.com   \n",
       "4      89403435   350.0  22-06-01      US  Business Insider   \n",
       "...         ...     ...       ...     ...               ...   \n",
       "80233  89566655  3298.0  22-06-30      US             Yahoo   \n",
       "80234  89566656   614.0  22-06-30      US             Yahoo   \n",
       "80235  89566657   287.0  22-06-30      US             Yahoo   \n",
       "80236  89566570   384.0  22-06-30      US          The Hill   \n",
       "80237  89566572  1044.0  22-06-30      US          The Hill   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.yahoo.com/lifestyle/lego-star-wars...   \n",
       "1      https://www.axios.com/2022/06/01/fbi-iran-hack...   \n",
       "2      https://www.axios.com/local/twin-cities/2022/0...   \n",
       "3      https://www.boston.com/community/music-club/me...   \n",
       "4      https://www.businessinsider.com/pamplona-priva...   \n",
       "...                                                  ...   \n",
       "80233  https://www.yahoo.com/lifestyle/11-men-share-e...   \n",
       "80234  https://www.yahoo.com/lifestyle/yes-ice-cream-...   \n",
       "80235  https://www.yahoo.com/news/football-rumours-bo...   \n",
       "80236  https://thehill.com/changing-america/enrichmen...   \n",
       "80237  https://thehill.com/homenews/campaign/3541597-...   \n",
       "\n",
       "                                                headline  \n",
       "0      'LEGO Star Wars: The Skywalker Saga' is loaded...  \n",
       "1      FBI head: Agency blocked Iranian cyberattack o...  \n",
       "2                        Jesse Ventura turns to Substack  \n",
       "3      Meet solo artist Adi Sun, one the top singer-s...  \n",
       "4      A private equity company wants to cut ties wit...  \n",
       "...                                                  ...  \n",
       "80233  11 men share their experiences of abortion aft...  \n",
       "80234  Yes, You Can Have Ice Cream Delivered Straight...  \n",
       "80235  Borussia Dortmund set Jude Bellingham's price ...  \n",
       "80236  New Jersey is losing residents to states like ...  \n",
       "80237       Five takeaways from the finalized House maps  \n",
       "\n",
       "[80238 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-22-06.txt\"  # Replace 'your_file_name.txt' with the actual file name\n",
    "\n",
    "# check if the path is a valid file and ends with '.txt'\n",
    "if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "    try:\n",
    "        # read the file into a dataframe, skipping bad lines\n",
    "        sources_22_06 = pd.read_csv(\n",
    "            file_path, \n",
    "            delimiter='\\t', \n",
    "            encoding='ISO-8859-1',\n",
    "            on_bad_lines='skip'  # Skip lines with too many or too few fields\n",
    "        )\n",
    "        \n",
    "        # define and assign column names\n",
    "        column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "        sources_22_06.columns = column_names\n",
    "        \n",
    "        # display the dataframe\n",
    "        sources_22_06\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError in file: {file_path}\")\n",
    "        print(e)\n",
    "        # log the problematic file\n",
    "        with open(\"/work/LauraSørineVoldgaard#8191/problematic_files.log\", \"a\") as log_file:\n",
    "            log_file.write(f\"ParserError in file: {file_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error in file: {file_path}. Error: {e}\")\n",
    "else:\n",
    "    print(f\"The specified file does not exist or is not a '.txt' file: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_22_06 = sources_22_06[sources_22_06[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_22_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79d22c7f-6eff-435a-bdb6-52e88b1e4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/sus_sources/sources_22_06_susnomore.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sources_22_06.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ec521-38da-4088-8793-bd8ef47e9823",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "283056b4-2790-4e5e-8709-4275b956b178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91204800</td>\n",
       "      <td>Secretary of State Antony Blinken pushed back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91204802</td>\n",
       "      <td>Medical records indicated the 4-month-old died...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91204803</td>\n",
       "      <td>Two decades later, French cinema still has eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91204804</td>\n",
       "      <td>You might have noticed that many of the same R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91204805</td>\n",
       "      <td>An antiabortion advocate prays outside the Sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85024</th>\n",
       "      <td>91852197</td>\n",
       "      <td>Raleigh, N.C. -- State House lawmakers have gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85025</th>\n",
       "      <td>91852198</td>\n",
       "      <td>Top General Assembly leaders said there was no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85026</th>\n",
       "      <td>91852199</td>\n",
       "      <td>The budget puts aside $1 billion into a new St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85027</th>\n",
       "      <td>91852280</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85028</th>\n",
       "      <td>91852280</td>\n",
       "      <td>&lt;p&gt; Dyson Dyson Daniels Daniels is is congratu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85029 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID                                               body\n",
       "0      91204800  Secretary of State Antony Blinken pushed back ...\n",
       "1      91204802  Medical records indicated the 4-month-old died...\n",
       "2      91204803  Two decades later, French cinema still has eno...\n",
       "3      91204804  You might have noticed that many of the same R...\n",
       "4      91204805  An antiabortion advocate prays outside the Sup...\n",
       "...         ...                                                ...\n",
       "85024  91852197  Raleigh, N.C. -- State House lawmakers have gi...\n",
       "85025  91852198  Top General Assembly leaders said there was no...\n",
       "85026  91852199  The budget puts aside $1 billion into a new St...\n",
       "85027  91852280                                                   \n",
       "85028  91852280  <p> Dyson Dyson Daniels Daniels is is congratu...\n",
       "\n",
       "[85029 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-06/22-06-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-06/22-06-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-06/22-06-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-06/22-06-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-06/22-06-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_22_06 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "text_22_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91fb7192-7526-40c5-b5f9-c27987c4ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  sources   texts\n",
      "0  21-08   150012  154411\n",
      "1  22-10    87596   89224\n",
      "2  22-05    85300   88880\n",
      "3  24-05    58737   59595\n",
      "4  22-09   108644  114876\n",
      "5  22-06    80238   85029\n"
     ]
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe for text_22_10 and sources_22_10\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\", \"22-10\", \"22-05\", \"24-05\", \"22-09\", \"22-06\"],  # Column for the months\n",
    "    \"sources\": [len(sources_21_08), len(sources_22_10), len(sources_22_05), len(sources_24_05), len(sources_22_09), len(sources_22_06)],  # Number of rows in sources dataframes\n",
    "    \"texts\": [len(text_21_08), len(text_22_10), len(text_22_05), len(text_24_05), len(text_22_09), len(text_22_06)]  # Number of rows in text dataframes\n",
    "})\n",
    "\n",
    "# Display the sus_months dataframe\n",
    "print(sus_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869bbc7-b95c-4b74-9572-2b62af456ed9",
   "metadata": {},
   "source": [
    "## 22-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e2a91-5445-47e0-9c2a-05fba68b33e8",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d1295e8-77b0-40de-bfcb-a69382308b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_806/842772877.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sources_22_03 = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53716555</td>\n",
       "      <td>524.0</td>\n",
       "      <td>22-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>myfox8.com</td>\n",
       "      <td>https://myfox8.com/news/north-carolina/north-c...</td>\n",
       "      <td>North Carolina Department of Revenue is ready ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53716562</td>\n",
       "      <td>446.0</td>\n",
       "      <td>22-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>statesman.com</td>\n",
       "      <td>https://www.statesman.com/story/news/politics/...</td>\n",
       "      <td>Greg Casar declares victory in Texas primary f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53716571</td>\n",
       "      <td>355.0</td>\n",
       "      <td>22-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>engadget.com</td>\n",
       "      <td>https://www.engadget.com/apple-russia-online-s...</td>\n",
       "      <td>Apple halts sales of all products in Russia | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53716846</td>\n",
       "      <td>664.0</td>\n",
       "      <td>22-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>dailyprogress.com</td>\n",
       "      <td>https://dailyprogress.com/lifestyles/cities-wi...</td>\n",
       "      <td>Cities with the most people taking road trips ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53716849</td>\n",
       "      <td>902.0</td>\n",
       "      <td>22-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>dailyprogress.com</td>\n",
       "      <td>https://dailyprogress.com/news/national/govt-a...</td>\n",
       "      <td>New Mexico Gov. signs education bills, $10k te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128956</th>\n",
       "      <td>89014813</td>\n",
       "      <td>722.0</td>\n",
       "      <td>22-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Minneapolis Star Tribune on MSN.com</td>\n",
       "      <td>https://www.msn.com/en-us/sports/nhl/seven-gam...</td>\n",
       "      <td>Seven-game win streak over for Wild after OT l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128957</th>\n",
       "      <td>89014817</td>\n",
       "      <td>678.0</td>\n",
       "      <td>22-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Orlando Sentinel</td>\n",
       "      <td>https://www.orlandosentinel.com/sports/florida...</td>\n",
       "      <td>Gators coach Billy Napier will be aggressive i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128958</th>\n",
       "      <td>89014820</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>22-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Sports Illustrated</td>\n",
       "      <td>https://www.si.com/curling/news/men-with-broom...</td>\n",
       "      <td>Men With Brooms Turns 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128959</th>\n",
       "      <td>89014821</td>\n",
       "      <td>200.0</td>\n",
       "      <td>22-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Sports Illustrated</td>\n",
       "      <td>https://www.si.com/tv/mlb-spring-training/chic...</td>\n",
       "      <td>How to Watch Chicago White Sox at Cincinnati R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128960</th>\n",
       "      <td>89014591</td>\n",
       "      <td>596.0</td>\n",
       "      <td>22-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>NFL</td>\n",
       "      <td>https://www.nfl.com/news/new-saints-qb-andy-da...</td>\n",
       "      <td>New Saints QB Andy Dalton ready to 'work with'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128961 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID   words      date country  \\\n",
       "0       53716555   524.0  22-03-01      US   \n",
       "1       53716562   446.0  22-03-01      US   \n",
       "2       53716571   355.0  22-03-01      US   \n",
       "3       53716846   664.0  22-03-01      US   \n",
       "4       53716849   902.0  22-03-01      US   \n",
       "...          ...     ...       ...     ...   \n",
       "128956  89014813   722.0  22-03-31      US   \n",
       "128957  89014817   678.0  22-03-31      US   \n",
       "128958  89014820  1018.0  22-03-31      US   \n",
       "128959  89014821   200.0  22-03-31      US   \n",
       "128960  89014591   596.0  22-03-31      US   \n",
       "\n",
       "                                     source  \\\n",
       "0                                myfox8.com   \n",
       "1                             statesman.com   \n",
       "2                              engadget.com   \n",
       "3                         dailyprogress.com   \n",
       "4                         dailyprogress.com   \n",
       "...                                     ...   \n",
       "128956  Minneapolis Star Tribune on MSN.com   \n",
       "128957                     Orlando Sentinel   \n",
       "128958                   Sports Illustrated   \n",
       "128959                   Sports Illustrated   \n",
       "128960                                  NFL   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://myfox8.com/news/north-carolina/north-c...   \n",
       "1       https://www.statesman.com/story/news/politics/...   \n",
       "2       https://www.engadget.com/apple-russia-online-s...   \n",
       "3       https://dailyprogress.com/lifestyles/cities-wi...   \n",
       "4       https://dailyprogress.com/news/national/govt-a...   \n",
       "...                                                   ...   \n",
       "128956  https://www.msn.com/en-us/sports/nhl/seven-gam...   \n",
       "128957  https://www.orlandosentinel.com/sports/florida...   \n",
       "128958  https://www.si.com/curling/news/men-with-broom...   \n",
       "128959  https://www.si.com/tv/mlb-spring-training/chic...   \n",
       "128960  https://www.nfl.com/news/new-saints-qb-andy-da...   \n",
       "\n",
       "                                                 headline  \n",
       "0       North Carolina Department of Revenue is ready ...  \n",
       "1       Greg Casar declares victory in Texas primary f...  \n",
       "2       Apple halts sales of all products in Russia | ...  \n",
       "3       Cities with the most people taking road trips ...  \n",
       "4       New Mexico Gov. signs education bills, $10k te...  \n",
       "...                                                   ...  \n",
       "128956  Seven-game win streak over for Wild after OT l...  \n",
       "128957  Gators coach Billy Napier will be aggressive i...  \n",
       "128958                           Men With Brooms Turns 20  \n",
       "128959  How to Watch Chicago White Sox at Cincinnati R...  \n",
       "128960  New Saints QB Andy Dalton ready to 'work with'...  \n",
       "\n",
       "[128961 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-22-03.txt\"  # Replace 'your_file_name.txt' with the actual file name\n",
    "\n",
    "# check if the path is a valid file and ends with '.txt'\n",
    "if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "    try:\n",
    "        # read the file into a dataframe, skipping bad lines\n",
    "        sources_22_03 = pd.read_csv(\n",
    "            file_path, \n",
    "            delimiter='\\t', \n",
    "            encoding='ISO-8859-1',\n",
    "            on_bad_lines='skip'  # Skip lines with too many or too few fields\n",
    "        )\n",
    "        \n",
    "        # define and assign column names\n",
    "        column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "        sources_22_03.columns = column_names\n",
    "        \n",
    "        # display the dataframe\n",
    "        sources_22_03\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError in file: {file_path}\")\n",
    "        print(e)\n",
    "        # log the problematic file\n",
    "        with open(\"/work/LauraSørineVoldgaard#8191/problematic_files.log\", \"a\") as log_file:\n",
    "            log_file.write(f\"ParserError in file: {file_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error in file: {file_path}. Error: {e}\")\n",
    "else:\n",
    "    print(f\"The specified file does not exist or is not a '.txt' file: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_22_03 = sources_22_03[sources_22_03[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_22_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "502956c0-9b20-451c-bae1-b6d8588b5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/sus_sources/sources_22_03_susnomore.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sources_22_03.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f186846-3aa4-476a-bf53-d8d8574b94f7",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f833eaa9-5fec-4e37-8eca-2a96bc52cfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33825603</td>\n",
       "      <td>Shares decline after Russia invades Ukraine.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33825610</td>\n",
       "      <td>Satellite images taken on Monday show a Russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33825612</td>\n",
       "      <td>Overall employment might be the easiest way to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33825613</td>\n",
       "      <td>DRESDEN, Germany -- First vaccine opponents at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33825614</td>\n",
       "      <td>The Turkish and Russian leaders have found the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136903</th>\n",
       "      <td>89014893</td>\n",
       "      <td>Twitter has over 1 billion accounts, but only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136904</th>\n",
       "      <td>89014894</td>\n",
       "      <td>The West has proclaimed Ukraine's victory in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136905</th>\n",
       "      <td>89014895</td>\n",
       "      <td>\" After much thought and consideration, the Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136906</th>\n",
       "      <td>89014896</td>\n",
       "      <td>During an interview with GB News anchor Dan Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136907</th>\n",
       "      <td>89014899</td>\n",
       "      <td>WASHINGTON -- Republicans on Capitol Hill foun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136908 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               body\n",
       "0       33825603  Shares decline after Russia invades Ukraine.\\n...\n",
       "1       33825610  Satellite images taken on Monday show a Russia...\n",
       "2       33825612  Overall employment might be the easiest way to...\n",
       "3       33825613  DRESDEN, Germany -- First vaccine opponents at...\n",
       "4       33825614  The Turkish and Russian leaders have found the...\n",
       "...          ...                                                ...\n",
       "136903  89014893  Twitter has over 1 billion accounts, but only ...\n",
       "136904  89014894  The West has proclaimed Ukraine's victory in t...\n",
       "136905  89014895  \" After much thought and consideration, the Ra...\n",
       "136906  89014896  During an interview with GB News anchor Dan Wo...\n",
       "136907  89014899  WASHINGTON -- Republicans on Capitol Hill foun...\n",
       "\n",
       "[136908 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-03/22-03-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-03/22-03-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-03/22-03-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-03/22-03-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-22-03/22-03-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_22_03 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "text_22_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a1832fe-4bd5-4bb7-9245-4d5ee0f65dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  sources   texts\n",
      "0  21-08   150012  154411\n",
      "1  22-10    87596   89224\n",
      "2  22-05    85300   88880\n",
      "3  24-05    58737   59595\n",
      "4  22-09   108644  114876\n",
      "5  22-06    80238   85029\n",
      "6  22-03   128961  136908\n"
     ]
    }
   ],
   "source": [
    "# Create the \"sus_months\" dataframe for text_22_10 and sources_22_10\n",
    "sus_months = pd.DataFrame({\n",
    "    \"month\": [\"21-08\", \"22-10\", \"22-05\", \"24-05\", \"22-09\", \"22-06\", \"22-03\"],  # Column for the months\n",
    "    \"sources\": [len(sources_21_08), len(sources_22_10), len(sources_22_05), len(sources_24_05), len(sources_22_09), len(sources_22_06), len(sources_22_03)],  # Number of rows in sources dataframes\n",
    "    \"texts\": [len(text_21_08), len(text_22_10), len(text_22_05), len(text_24_05), len(text_22_09), len(text_22_06), len(text_22_03)]  # Number of rows in text dataframes\n",
    "})\n",
    "\n",
    "# Display the sus_months dataframe\n",
    "print(sus_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532768c8-27b8-430c-94d0-3729b0aad816",
   "metadata": {},
   "source": [
    "# 23-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692b240-8486-4a54-8b2f-db12d4fc626c",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bae46a-5eab-49fc-8af0-84bb3958e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90659700</td>\n",
       "      <td>827</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/belarus-leader-fully-su...</td>\n",
       "      <td>Belarus leader 'fully supports' China's Ukrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90659707</td>\n",
       "      <td>184</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/jalen-carter-charged-re...</td>\n",
       "      <td>Jalen Carter charged with reckless driving in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90659710</td>\n",
       "      <td>2344</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/male-contraceptive-pill...</td>\n",
       "      <td>`The male contraceptive pill is on its way - b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90659714</td>\n",
       "      <td>415</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>New York Post</td>\n",
       "      <td>https://nypost.com/2023/02/09/ex-fbi-agent-nic...</td>\n",
       "      <td>Ex-FBI agent Nicole Parker: Bureau `politicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90659753</td>\n",
       "      <td>441</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>New York Post</td>\n",
       "      <td>https://nypost.com/2023/02/28/brendan-fraser-r...</td>\n",
       "      <td>Brendan Fraser reveals he almost died shooting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72940</th>\n",
       "      <td>97896045</td>\n",
       "      <td>331</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/prestoncountynews/news/tunn...</td>\n",
       "      <td>Tunnelton man charged with making explosive de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72941</th>\n",
       "      <td>97896046</td>\n",
       "      <td>694</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/sports/highschool/grafton-g...</td>\n",
       "      <td>Grafton girls track take 7th in season opening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72942</th>\n",
       "      <td>97896047</td>\n",
       "      <td>805</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/sports/highschool/rcb-softb...</td>\n",
       "      <td>RCB softball scores 31 runs in seven innings t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72943</th>\n",
       "      <td>97896048</td>\n",
       "      <td>837</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/sports/highschool/rcb-withs...</td>\n",
       "      <td>RCB withstands Elkins' late comeback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72944</th>\n",
       "      <td>97896052</td>\n",
       "      <td>1585</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/newsfeed/entertainment/broo...</td>\n",
       "      <td>Brooke Shields takes charge of her story in '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72945 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID words      date country         source  \\\n",
       "0      90659700   827  23-03-01      US     YAHOO!News   \n",
       "1      90659707   184  23-03-01      US     YAHOO!News   \n",
       "2      90659710  2344  23-03-01      US     YAHOO!News   \n",
       "3      90659714   415  23-03-01      US  New York Post   \n",
       "4      90659753   441  23-03-01      US  New York Post   \n",
       "...         ...   ...       ...     ...            ...   \n",
       "72940  97896045   331  23-03-31      US     wvnews.com   \n",
       "72941  97896046   694  23-03-31      US     wvnews.com   \n",
       "72942  97896047   805  23-03-31      US     wvnews.com   \n",
       "72943  97896048   837  23-03-31      US     wvnews.com   \n",
       "72944  97896052  1585  23-03-31      US     wvnews.com   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://news.yahoo.com/belarus-leader-fully-su...   \n",
       "1      https://news.yahoo.com/jalen-carter-charged-re...   \n",
       "2      https://news.yahoo.com/male-contraceptive-pill...   \n",
       "3      https://nypost.com/2023/02/09/ex-fbi-agent-nic...   \n",
       "4      https://nypost.com/2023/02/28/brendan-fraser-r...   \n",
       "...                                                  ...   \n",
       "72940  https://wvnews.com/prestoncountynews/news/tunn...   \n",
       "72941  https://wvnews.com/sports/highschool/grafton-g...   \n",
       "72942  https://wvnews.com/sports/highschool/rcb-softb...   \n",
       "72943  https://wvnews.com/sports/highschool/rcb-withs...   \n",
       "72944  https://wvnews.com/newsfeed/entertainment/broo...   \n",
       "\n",
       "                                                headline  \n",
       "0      Belarus leader 'fully supports' China's Ukrain...  \n",
       "1      Jalen Carter charged with reckless driving in ...  \n",
       "2      `The male contraceptive pill is on its way - b...  \n",
       "3      Ex-FBI agent Nicole Parker: Bureau `politicall...  \n",
       "4      Brendan Fraser reveals he almost died shooting...  \n",
       "...                                                  ...  \n",
       "72940  Tunnelton man charged with making explosive de...  \n",
       "72941  Grafton girls track take 7th in season opening...  \n",
       "72942  RCB softball scores 31 runs in seven innings t...  \n",
       "72943               RCB withstands Elkins' late comeback  \n",
       "72944   Brooke Shields takes charge of her story in '...  \n",
       "\n",
       "[72945 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import csv  # Required for quoting constants like QUOTE_NONE\n",
    "\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-23-03.txt\"\n",
    "\n",
    "# Initialize lists to hold valid and invalid rows\n",
    "valid_rows = []\n",
    "invalid_rows = []\n",
    "\n",
    "# Set maximum row limit\n",
    "max_rows_to_process = 313875\n",
    "\n",
    "try:\n",
    "    # Read the file without chunks, handle quotes and force data types\n",
    "    data = pd.read_csv(\n",
    "        file_path,\n",
    "        delimiter='\\t',\n",
    "        encoding='ISO-8859-1',\n",
    "        on_bad_lines='warn',\n",
    "        nrows=max_rows_to_process,\n",
    "        quoting=csv.QUOTE_NONE,  # Treat all text literally, do not treat quotes as special\n",
    "        escapechar='\\\\',  # Escape special characters if needed\n",
    "        dtype=str,  # Force all columns to be read as strings\n",
    "        low_memory=False  # Avoid mixed-type warnings\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values with empty strings to avoid issues with non-iterable types\n",
    "    data.fillna('', inplace=True)\n",
    "\n",
    "    # Assign column names (adjust based on actual structure if needed)\n",
    "    data.columns = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "\n",
    "    # Decode HTML entities in text fields\n",
    "    data[\"headline\"] = data[\"headline\"].apply(html.unescape)\n",
    "    data[\"url\"] = data[\"url\"].apply(html.unescape)\n",
    "\n",
    "    # Filter rows into valid and invalid lists\n",
    "    for index, row in data.iterrows():\n",
    "        if all(row.notnull()) and len(row) == 7:  # Ensure all fields are non-null and correctly structured\n",
    "            valid_rows.append(row)\n",
    "        else:\n",
    "            invalid_rows.append(row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the file: {e}\")\n",
    "\n",
    "# Create a DataFrame from the valid rows\n",
    "sources_23_03 = pd.DataFrame(valid_rows, columns=[\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"])\n",
    "\n",
    "# Display invalid rows for debugging, if needed\n",
    "print(f\"Invalid rows: {len(invalid_rows)}\")\n",
    "for row in invalid_rows[:5]:  # Display a sample of invalid rows\n",
    "    print(row)\n",
    "\n",
    "# Display the final DataFrame\n",
    "sources_23_03\n",
    "\n",
    "# Filter the DataFrame for rows where the \"country\" column is \"US\"\n",
    "sources_23_03 = sources_23_03[sources_23_03[\"country\"] == \"US\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_23_03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461702cd-bccf-4659-bd89-be8752311090",
   "metadata": {},
   "source": [
    "## Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28c1c32-c53d-475d-bf5f-4abcbee3f200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          textID                                               body\n",
      "0       90659700  Belarus President Alexander Lukashenko told hi...\n",
      "1       90659707  On Wednesday at 10:30 AM at the NFL Scouting C...\n",
      "2       90659710  Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...\n",
      "3       90659714  Former FBI Special Agent Nicole Parker testifi...\n",
      "4       90659803  An image of Douglas Rushkoff, a man who is kno...\n",
      "...          ...                                                ...\n",
      "149103  97895897  John Allore was riding his bicycle around 7 a....\n",
      "149104  97895898  The images, which first appeared on a Facebook...\n",
      "149105  97895899  \" The best chance for storms will be from 10 a...\n",
      "149106  97895981  Amazon has impressive deals including the ARM ...\n",
      "149107  97895988  The Town of Waynesville had a strong plan befo...\n",
      "\n",
      "[149108 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-23-03/23-03-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-23-03/23-03-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-23-03/23-03-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-23-03/23-03-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-23-03/23-03-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_23_03 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(text_23_03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea33cb75-af24-4b8f-9f68-c931ab4be368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID       int64\n",
      "words       object\n",
      "date        object\n",
      "country     object\n",
      "source      object\n",
      "url         object\n",
      "headline    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'textID' to numeric, and raise an error if there are invalid values\n",
    "sources_23_03['textID'] = pd.to_numeric(sources_23_03['textID'], errors='raise')\n",
    "\n",
    "# Convert 'textID' to integers\n",
    "sources_23_03['textID'] = sources_23_03['textID'].astype(int)\n",
    "\n",
    "# Verify the data type\n",
    "print(sources_23_03.dtypes)  # 'textID' should now be int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39130ef2-ea7e-40d3-9f7e-d928246495ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72945\n",
      "149108\n"
     ]
    }
   ],
   "source": [
    "print(len(sources_23_03))\n",
    "print(len(text_23_03))\n",
    "#print(len(merged_23_03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f49abd3-15fe-41ed-96d6-938c568e2d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "76165\n"
     ]
    }
   ],
   "source": [
    "print(sources_23_03['textID'].duplicated().sum())  # Number of duplicate rows in sources_23_03\n",
    "print(text_23_03['textID'].duplicated().sum())    # Number of duplicate rows in text_23_03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb231da-3db2-4633-b86b-7b37edc5fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90659700</td>\n",
       "      <td>Belarus President Alexander Lukashenko told hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90659707</td>\n",
       "      <td>On Wednesday at 10:30 AM at the NFL Scouting C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90659710</td>\n",
       "      <td>Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90659714</td>\n",
       "      <td>Former FBI Special Agent Nicole Parker testifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90659803</td>\n",
       "      <td>An image of Douglas Rushkoff, a man who is kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149102</th>\n",
       "      <td>97895894</td>\n",
       "      <td>A WRAL Weather Alert Day has been issued for S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149103</th>\n",
       "      <td>97895897</td>\n",
       "      <td>John Allore was riding his bicycle around 7 a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149104</th>\n",
       "      <td>97895898</td>\n",
       "      <td>The images, which first appeared on a Facebook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149105</th>\n",
       "      <td>97895899</td>\n",
       "      <td>\" The best chance for storms will be from 10 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149106</th>\n",
       "      <td>97895981</td>\n",
       "      <td>Amazon has impressive deals including the ARM ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149099 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               body\n",
       "0       90659700  Belarus President Alexander Lukashenko told hi...\n",
       "1       90659707  On Wednesday at 10:30 AM at the NFL Scouting C...\n",
       "2       90659710  Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...\n",
       "3       90659714  Former FBI Special Agent Nicole Parker testifi...\n",
       "4       90659803  An image of Douglas Rushkoff, a man who is kno...\n",
       "...          ...                                                ...\n",
       "149102  97895894  A WRAL Weather Alert Day has been issued for S...\n",
       "149103  97895897  John Allore was riding his bicycle around 7 a....\n",
       "149104  97895898  The images, which first appeared on a Facebook...\n",
       "149105  97895899  \" The best chance for storms will be from 10 a...\n",
       "149106  97895981  Amazon has impressive deals including the ARM ...\n",
       "\n",
       "[149099 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of duplicate rows (before removing the NaN in body column rows)\n",
    "print(text_23_03['textID'].duplicated().sum())    # Number of duplicate rows\n",
    "\n",
    "# number of duplicate rows (after removing the NaN in body column rows)\n",
    "duplicates = text_23_03[text_23_03['body'].duplicated(keep=False)]\n",
    "duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7756af13-5276-4aec-af58-feaefebee7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows (all columns): 74549\n",
      "Number of duplicate rows (textID only): 76165\n",
      "Number of duplicate rows (all columns): 0\n"
     ]
    }
   ],
   "source": [
    "# Count duplicates before removal\n",
    "print(f\"Number of duplicate rows (all columns): {text_23_03.duplicated().sum()}\")\n",
    "print(f\"Number of duplicate rows (textID only): {text_23_03['textID'].duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates based on the entire row (all columns)\n",
    "text_23_03 = text_23_03.drop_duplicates()\n",
    "\n",
    "# Remove duplicates based only on 'textID' column\n",
    "text_23_03 = text_23_03.drop_duplicates(subset=['textID'])\n",
    "\n",
    "# Remove duplicates based on 'body' column and keep the first occurrence\n",
    "text_23_03 = text_23_03.drop_duplicates(subset=['body'], keep='first')\n",
    "\n",
    "# Display number of duplicates after removal\n",
    "print(f\"Number of duplicate rows (all columns): {text_23_03.duplicated().sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad171c2-f2a1-4b15-a04f-0c718c52a142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90659700</td>\n",
       "      <td>Belarus President Alexander Lukashenko told hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90659707</td>\n",
       "      <td>On Wednesday at 10:30 AM at the NFL Scouting C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90659710</td>\n",
       "      <td>Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90659714</td>\n",
       "      <td>Former FBI Special Agent Nicole Parker testifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90659803</td>\n",
       "      <td>An image of Douglas Rushkoff, a man who is kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135320</th>\n",
       "      <td>97895894</td>\n",
       "      <td>A WRAL Weather Alert Day has been issued for S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135321</th>\n",
       "      <td>97895897</td>\n",
       "      <td>John Allore was riding his bicycle around 7 a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135322</th>\n",
       "      <td>97895898</td>\n",
       "      <td>The images, which first appeared on a Facebook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135323</th>\n",
       "      <td>97895899</td>\n",
       "      <td>\" The best chance for storms will be from 10 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135324</th>\n",
       "      <td>97895981</td>\n",
       "      <td>Amazon has impressive deals including the ARM ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71015 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               body\n",
       "0       90659700  Belarus President Alexander Lukashenko told hi...\n",
       "1       90659707  On Wednesday at 10:30 AM at the NFL Scouting C...\n",
       "2       90659710  Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...\n",
       "3       90659714  Former FBI Special Agent Nicole Parker testifi...\n",
       "4       90659803  An image of Douglas Rushkoff, a man who is kno...\n",
       "...          ...                                                ...\n",
       "135320  97895894  A WRAL Weather Alert Day has been issued for S...\n",
       "135321  97895897  John Allore was riding his bicycle around 7 a....\n",
       "135322  97895898  The images, which first appeared on a Facebook...\n",
       "135323  97895899  \" The best chance for storms will be from 10 a...\n",
       "135324  97895981  Amazon has impressive deals including the ARM ...\n",
       "\n",
       "[71015 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display text_23_03 without duplicate rows\n",
    "text_23_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb79d5a-5ece-4394-a8ec-8846a5d30858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90659700</td>\n",
       "      <td>827</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/belarus-leader-fully-su...</td>\n",
       "      <td>Belarus leader 'fully supports' China's Ukrain...</td>\n",
       "      <td>Belarus President Alexander Lukashenko told hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90659707</td>\n",
       "      <td>184</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/jalen-carter-charged-re...</td>\n",
       "      <td>Jalen Carter charged with reckless driving in ...</td>\n",
       "      <td>On Wednesday at 10:30 AM at the NFL Scouting C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90659710</td>\n",
       "      <td>2344</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!News</td>\n",
       "      <td>https://news.yahoo.com/male-contraceptive-pill...</td>\n",
       "      <td>`The male contraceptive pill is on its way - b...</td>\n",
       "      <td>Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90659714</td>\n",
       "      <td>415</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>New York Post</td>\n",
       "      <td>https://nypost.com/2023/02/09/ex-fbi-agent-nic...</td>\n",
       "      <td>Ex-FBI agent Nicole Parker: Bureau `politicall...</td>\n",
       "      <td>Former FBI Special Agent Nicole Parker testifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90659753</td>\n",
       "      <td>441</td>\n",
       "      <td>23-03-01</td>\n",
       "      <td>US</td>\n",
       "      <td>New York Post</td>\n",
       "      <td>https://nypost.com/2023/02/28/brendan-fraser-r...</td>\n",
       "      <td>Brendan Fraser reveals he almost died shooting...</td>\n",
       "      <td>\" I was choked out accidentally, \" said Fraser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71009</th>\n",
       "      <td>97896045</td>\n",
       "      <td>331</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/prestoncountynews/news/tunn...</td>\n",
       "      <td>Tunnelton man charged with making explosive de...</td>\n",
       "      <td>TUNNELTON -- A Tunnelton man was charged with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71010</th>\n",
       "      <td>97896046</td>\n",
       "      <td>694</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/sports/highschool/grafton-g...</td>\n",
       "      <td>Grafton girls track take 7th in season opening...</td>\n",
       "      <td>BRIDGEPORT, W.Va. ( WV News ) -- The Grafton g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71011</th>\n",
       "      <td>97896047</td>\n",
       "      <td>805</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/sports/highschool/rcb-softb...</td>\n",
       "      <td>RCB softball scores 31 runs in seven innings t...</td>\n",
       "      <td>CLARKSBURG, W.Va. ( WV News ) -- Robert C. Byr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71012</th>\n",
       "      <td>97896048</td>\n",
       "      <td>837</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/sports/highschool/rcb-withs...</td>\n",
       "      <td>RCB withstands Elkins' late comeback</td>\n",
       "      <td>CLARKSBURG, W.Va. ( WV News ) -- A day after e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71013</th>\n",
       "      <td>97896052</td>\n",
       "      <td>1585</td>\n",
       "      <td>23-03-31</td>\n",
       "      <td>US</td>\n",
       "      <td>wvnews.com</td>\n",
       "      <td>https://wvnews.com/newsfeed/entertainment/broo...</td>\n",
       "      <td>Brooke Shields takes charge of her story in '...</td>\n",
       "      <td>FILE - Brooke Shields poses for a portrait to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71014 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID words      date country         source  \\\n",
       "0      90659700   827  23-03-01      US     YAHOO!News   \n",
       "1      90659707   184  23-03-01      US     YAHOO!News   \n",
       "2      90659710  2344  23-03-01      US     YAHOO!News   \n",
       "3      90659714   415  23-03-01      US  New York Post   \n",
       "4      90659753   441  23-03-01      US  New York Post   \n",
       "...         ...   ...       ...     ...            ...   \n",
       "71009  97896045   331  23-03-31      US     wvnews.com   \n",
       "71010  97896046   694  23-03-31      US     wvnews.com   \n",
       "71011  97896047   805  23-03-31      US     wvnews.com   \n",
       "71012  97896048   837  23-03-31      US     wvnews.com   \n",
       "71013  97896052  1585  23-03-31      US     wvnews.com   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://news.yahoo.com/belarus-leader-fully-su...   \n",
       "1      https://news.yahoo.com/jalen-carter-charged-re...   \n",
       "2      https://news.yahoo.com/male-contraceptive-pill...   \n",
       "3      https://nypost.com/2023/02/09/ex-fbi-agent-nic...   \n",
       "4      https://nypost.com/2023/02/28/brendan-fraser-r...   \n",
       "...                                                  ...   \n",
       "71009  https://wvnews.com/prestoncountynews/news/tunn...   \n",
       "71010  https://wvnews.com/sports/highschool/grafton-g...   \n",
       "71011  https://wvnews.com/sports/highschool/rcb-softb...   \n",
       "71012  https://wvnews.com/sports/highschool/rcb-withs...   \n",
       "71013  https://wvnews.com/newsfeed/entertainment/broo...   \n",
       "\n",
       "                                                headline  \\\n",
       "0      Belarus leader 'fully supports' China's Ukrain...   \n",
       "1      Jalen Carter charged with reckless driving in ...   \n",
       "2      `The male contraceptive pill is on its way - b...   \n",
       "3      Ex-FBI agent Nicole Parker: Bureau `politicall...   \n",
       "4      Brendan Fraser reveals he almost died shooting...   \n",
       "...                                                  ...   \n",
       "71009  Tunnelton man charged with making explosive de...   \n",
       "71010  Grafton girls track take 7th in season opening...   \n",
       "71011  RCB softball scores 31 runs in seven innings t...   \n",
       "71012               RCB withstands Elkins' late comeback   \n",
       "71013   Brooke Shields takes charge of her story in '...   \n",
       "\n",
       "                                                    body  \n",
       "0      Belarus President Alexander Lukashenko told hi...  \n",
       "1      On Wednesday at 10:30 AM at the NFL Scouting C...  \n",
       "2      Eloise Hendy\\nMarch 1, 2023, 8:07 AM*9 min rea...  \n",
       "3      Former FBI Special Agent Nicole Parker testifi...  \n",
       "4      \" I was choked out accidentally, \" said Fraser...  \n",
       "...                                                  ...  \n",
       "71009  TUNNELTON -- A Tunnelton man was charged with ...  \n",
       "71010  BRIDGEPORT, W.Va. ( WV News ) -- The Grafton g...  \n",
       "71011  CLARKSBURG, W.Va. ( WV News ) -- Robert C. Byr...  \n",
       "71012  CLARKSBURG, W.Va. ( WV News ) -- A day after e...  \n",
       "71013  FILE - Brooke Shields poses for a portrait to ...  \n",
       "\n",
       "[71014 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_23_03 = sources_23_03.merge(text_23_03, on = \"textID\", how = \"inner\") # join sources dataframe with their corresponding article content using the textIDs, keeping only the articles where text IDs match. How = left to ensure that it is a dataframe and series, not a list\n",
    "merged_23_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f70704c-b18d-436e-b9cf-c7db93b891a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/LauraSørineVoldgaard#8191/data/merged_23_03.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "merged_23_03.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12322e-8758-4d70-9fb3-c81110765866",
   "metadata": {},
   "source": [
    "# 24-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b3fec-921f-4e1f-9bc9-a1136bef4aff",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1472bd-f2f2-4e80-bdc8-31de128ebb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116932171</td>\n",
       "      <td>158</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>jpost.com</td>\n",
       "      <td>https://www.jpost.com/israel-news/article-826346\\</td>\n",
       "      <td>leaked to the Israeli media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116975644</td>\n",
       "      <td>435</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcbayarea.com</td>\n",
       "      <td>https://www.nbcbayarea.com/news/local/san-fran...</td>\n",
       "      <td>United Airlines attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116975645</td>\n",
       "      <td>137</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcbayarea.com</td>\n",
       "      <td>https://www.nbcbayarea.com/news/local/san-fran...</td>\n",
       "      <td>Nima Momeni trial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116975650</td>\n",
       "      <td>211</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcbayarea.com</td>\n",
       "      <td>https://www.nbcbayarea.com/decision-2024/harri...</td>\n",
       "      <td>Harris, Trump campaigns make final West Coast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116975651</td>\n",
       "      <td>275</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nbcbayarea.com</td>\n",
       "      <td>https://www.nbcbayarea.com/news/local/embattle...</td>\n",
       "      <td>Embattled San Jose councilman facing more call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107982</th>\n",
       "      <td>118313484</td>\n",
       "      <td>957</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/one-of-my-favorite-b...</td>\n",
       "      <td>One of my favorite big-screen tablets for wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107983</th>\n",
       "      <td>118313486</td>\n",
       "      <td>77</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/best-black-friday-be...</td>\n",
       "      <td>The 30+ best live Black Friday Best Buy deals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107984</th>\n",
       "      <td>118313498</td>\n",
       "      <td>1190</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/the-latest-version-o...</td>\n",
       "      <td>The latest version of my favorite Garmin smar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107985</th>\n",
       "      <td>118313502</td>\n",
       "      <td>1492</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/the-2-in-1-laptop-i-...</td>\n",
       "      <td>The 2-in-1 laptop I recommend to most people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107986</th>\n",
       "      <td>118313503</td>\n",
       "      <td>215</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/home-and-office/this-touchsc...</td>\n",
       "      <td>This touchscreen display adds Apple CarPlay o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107885 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID words      date country          source  \\\n",
       "0       116932171   158  24-11-01      US       jpost.com   \n",
       "1       116975644   435  24-11-01      US  nbcbayarea.com   \n",
       "2       116975645   137  24-11-01      US  nbcbayarea.com   \n",
       "3       116975650   211  24-11-01      US  nbcbayarea.com   \n",
       "4       116975651   275  24-11-01      US  nbcbayarea.com   \n",
       "...           ...   ...       ...     ...             ...   \n",
       "107982  118313484   957  24-11-30      US       zdnet.com   \n",
       "107983  118313486    77  24-11-30      US       zdnet.com   \n",
       "107984  118313498  1190  24-11-30      US       zdnet.com   \n",
       "107985  118313502  1492  24-11-30      US       zdnet.com   \n",
       "107986  118313503   215  24-11-30      US       zdnet.com   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.jpost.com/israel-news/article-826346\\   \n",
       "1       https://www.nbcbayarea.com/news/local/san-fran...   \n",
       "2       https://www.nbcbayarea.com/news/local/san-fran...   \n",
       "3       https://www.nbcbayarea.com/decision-2024/harri...   \n",
       "4       https://www.nbcbayarea.com/news/local/embattle...   \n",
       "...                                                   ...   \n",
       "107982  https://zdnet.com/article/one-of-my-favorite-b...   \n",
       "107983  https://zdnet.com/article/best-black-friday-be...   \n",
       "107984  https://zdnet.com/article/the-latest-version-o...   \n",
       "107985  https://zdnet.com/article/the-2-in-1-laptop-i-...   \n",
       "107986  https://zdnet.com/home-and-office/this-touchsc...   \n",
       "\n",
       "                                                 headline  \n",
       "0                             leaked to the Israeli media  \n",
       "1                                  United Airlines attack  \n",
       "2                                       Nima Momeni trial  \n",
       "3       Harris, Trump campaigns make final West Coast ...  \n",
       "4       Embattled San Jose councilman facing more call...  \n",
       "...                                                   ...  \n",
       "107982   One of my favorite big-screen tablets for wat...  \n",
       "107983   The 30+ best live Black Friday Best Buy deals...  \n",
       "107984   The latest version of my favorite Garmin smar...  \n",
       "107985   The 2-in-1 laptop I recommend to most people ...  \n",
       "107986   This touchscreen display adds Apple CarPlay o...  \n",
       "\n",
       "[107885 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/sources/sources-24-11.txt\"\n",
    "\n",
    "# Set maximum rows to process\n",
    "max_rows_to_process = 313875\n",
    "\n",
    "try:\n",
    "    # Read the file line by line and split manually on tab character\n",
    "    with open(file_path, encoding='ISO-8859-1') as file:\n",
    "        lines = file.readlines()[:max_rows_to_process]  # Limit rows if needed\n",
    "    \n",
    "    # Manually split each line on the tab character\n",
    "    data = [line.strip().split('\\t') for line in lines]\n",
    "\n",
    "    # Convert to a DataFrame\n",
    "    raw_data = pd.DataFrame(data)\n",
    "\n",
    "    # Assign column names (adjust these names based on your data)\n",
    "    raw_data.columns = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"headline\"]\n",
    "\n",
    "    # Inspect the DataFrame\n",
    "    #print(raw_data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the file: {e}\")\n",
    "\n",
    "# Filter for rows where country is \"US\"\n",
    "sources_24_11 = raw_data[raw_data[\"country\"] == \"US\"]\n",
    "\n",
    "# Save the cleaned and filtered DataFrame\n",
    "sources_24_11.to_csv(\"filtered-sources-24-11.csv\", index=False)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "sources_24_11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e620e4f2-fbf2-42b0-828d-0ceb56ce1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude rows with specific dates\n",
    "included_dates = ['24-11-01', '24-11-02', '24-11-03', '24-11-04', '24-11-05']\n",
    "df_filtered = sources_24_11[sources_24_11['date'].isin(included_dates)]\n",
    "\n",
    "# Display the filtered dataframe\n",
    "df_filtered\n",
    "\n",
    "# Save the filtered dataframe back to a new CSV file\n",
    "df_filtered.to_csv(\"filtered_sources-24-11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae86ff4-20ad-43c4-973f-252106d5c5f4",
   "metadata": {},
   "source": [
    "## Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47947605-ec2c-48d3-994d-49ce21ff7bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch in IDs and articles in file: /work/LauraSørineVoldgaard#8191/data/text/text-24-11/24-11-us3.txt\n",
      "Number of IDs: 21463, Number of Articles: 21462\n",
      "Empty article body detected for textID @@118192649\n",
      "          textID                                               body\n",
      "0      116953714  Former President Bill Clinton rallied a crowd ...\n",
      "1      116953716  Besides delivering gas to homes, the pipelines...\n",
      "2      116953717  Starting this month, Central Maine Power Co. c...\n",
      "3      116953718  Lawmakers have scaled back an ambitious propos...\n",
      "4      116953719  Gun rights advocates hold signs among the gun ...\n",
      "...          ...                                                ...\n",
      "85743  118313294  A New Hampshire man is being remembered as a r...\n",
      "85744  118313297  A woman is OK after she fell asleep at the whe...\n",
      "85745  118313484  Why you can trust ZDNET: ZDNET independently t...\n",
      "85746  118313486  Why you can trust ZDNET: ZDNET's expert staff ...\n",
      "85747  118313498  Why you can trust ZDNET: ZDNET independently t...\n",
      "\n",
      "[85748 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-11/24-11-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-11/24-11-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-11/24-11-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-11/24-11-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-24-11/24-11-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_24_11 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(text_24_11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b219add-92e3-441b-a8a4-a4141fcec1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID     int64\n",
      "body      object\n",
      "dtype: object\n",
      "textID       int64\n",
      "words       object\n",
      "date        object\n",
      "country     object\n",
      "source      object\n",
      "url         object\n",
      "headline    object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1089/3487416257.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sources_24_11['textID'] = sources_24_11['textID'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Convert 'textID' to integers\n",
    "text_24_11['textID'] = text_24_11['textID'].astype(int)\n",
    "sources_24_11['textID'] = sources_24_11['textID'].astype(int)\n",
    "\n",
    "\n",
    "# Verify the data type\n",
    "print(text_24_11.dtypes)  # 'textID' should now be int64\n",
    "print(sources_24_11.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093b3b42-6384-491a-a6a3-4063643a6592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116977976</td>\n",
       "      <td>358</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>oregonlive.com</td>\n",
       "      <td>https://www.oregonlive.com/pacific-northwest-n...</td>\n",
       "      <td>Pacific Northwest2 Oregon mushroom hunters res...</td>\n",
       "      <td>Two Oregon mushroom hunters have been rescued ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116977978</td>\n",
       "      <td>319</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>oregonlive.com</td>\n",
       "      <td>https://www.oregonlive.com/crime/2024/11/vanco...</td>\n",
       "      <td>Vancouver Mall shooting was a `targeted attack...</td>\n",
       "      <td>As of Friday morning, the shooter was still at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116977979</td>\n",
       "      <td>817</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>oregonlive.com</td>\n",
       "      <td>https://www.oregonlive.com/clark-county/2024/1...</td>\n",
       "      <td>Halloween shooting at Vancouver Mall kills 1, ...</td>\n",
       "      <td>One person was killed and two injured in a sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116977981</td>\n",
       "      <td>156</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>oregonlive.com</td>\n",
       "      <td>https://www.oregonlive.com/politics/2024/11/bo...</td>\n",
       "      <td>Boarded windows return to downtown Portland ah...</td>\n",
       "      <td>Updated: Nov. 01, 2024, 10:59 a.m.\\nPublished:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116977983</td>\n",
       "      <td>658</td>\n",
       "      <td>24-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>oregonlive.com</td>\n",
       "      <td>https://www.oregonlive.com/ducks/2024/11/orego...</td>\n",
       "      <td>Oregon football vs. Michigan preview: Ducks ma...</td>\n",
       "      <td>Updated: Nov. 01, 2024, 2:42 p.m.\\nPublished: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85164</th>\n",
       "      <td>118313484</td>\n",
       "      <td>957</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/one-of-my-favorite-b...</td>\n",
       "      <td>One of my favorite big-screen tablets for wat...</td>\n",
       "      <td>Why you can trust ZDNET: ZDNET independently t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85165</th>\n",
       "      <td>118313486</td>\n",
       "      <td>77</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/best-black-friday-be...</td>\n",
       "      <td>The 30+ best live Black Friday Best Buy deals...</td>\n",
       "      <td>Why you can trust ZDNET: ZDNET's expert staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85166</th>\n",
       "      <td>118313498</td>\n",
       "      <td>1190</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/the-latest-version-o...</td>\n",
       "      <td>The latest version of my favorite Garmin smar...</td>\n",
       "      <td>Why you can trust ZDNET: ZDNET independently t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85167</th>\n",
       "      <td>118313502</td>\n",
       "      <td>1492</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/article/the-2-in-1-laptop-i-...</td>\n",
       "      <td>The 2-in-1 laptop I recommend to most people ...</td>\n",
       "      <td>Why you can trust ZDNET: ZDNET independently t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85168</th>\n",
       "      <td>118313503</td>\n",
       "      <td>215</td>\n",
       "      <td>24-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>https://zdnet.com/home-and-office/this-touchsc...</td>\n",
       "      <td>This touchscreen display adds Apple CarPlay o...</td>\n",
       "      <td>Why you can trust ZDNET: ZDNET's expert staff ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85169 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID words      date country          source  \\\n",
       "0      116977976   358  24-11-01      US  oregonlive.com   \n",
       "1      116977978   319  24-11-01      US  oregonlive.com   \n",
       "2      116977979   817  24-11-01      US  oregonlive.com   \n",
       "3      116977981   156  24-11-01      US  oregonlive.com   \n",
       "4      116977983   658  24-11-01      US  oregonlive.com   \n",
       "...          ...   ...       ...     ...             ...   \n",
       "85164  118313484   957  24-11-30      US       zdnet.com   \n",
       "85165  118313486    77  24-11-30      US       zdnet.com   \n",
       "85166  118313498  1190  24-11-30      US       zdnet.com   \n",
       "85167  118313502  1492  24-11-30      US       zdnet.com   \n",
       "85168  118313503   215  24-11-30      US       zdnet.com   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.oregonlive.com/pacific-northwest-n...   \n",
       "1      https://www.oregonlive.com/crime/2024/11/vanco...   \n",
       "2      https://www.oregonlive.com/clark-county/2024/1...   \n",
       "3      https://www.oregonlive.com/politics/2024/11/bo...   \n",
       "4      https://www.oregonlive.com/ducks/2024/11/orego...   \n",
       "...                                                  ...   \n",
       "85164  https://zdnet.com/article/one-of-my-favorite-b...   \n",
       "85165  https://zdnet.com/article/best-black-friday-be...   \n",
       "85166  https://zdnet.com/article/the-latest-version-o...   \n",
       "85167  https://zdnet.com/article/the-2-in-1-laptop-i-...   \n",
       "85168  https://zdnet.com/home-and-office/this-touchsc...   \n",
       "\n",
       "                                                headline  \\\n",
       "0      Pacific Northwest2 Oregon mushroom hunters res...   \n",
       "1      Vancouver Mall shooting was a `targeted attack...   \n",
       "2      Halloween shooting at Vancouver Mall kills 1, ...   \n",
       "3      Boarded windows return to downtown Portland ah...   \n",
       "4      Oregon football vs. Michigan preview: Ducks ma...   \n",
       "...                                                  ...   \n",
       "85164   One of my favorite big-screen tablets for wat...   \n",
       "85165   The 30+ best live Black Friday Best Buy deals...   \n",
       "85166   The latest version of my favorite Garmin smar...   \n",
       "85167   The 2-in-1 laptop I recommend to most people ...   \n",
       "85168   This touchscreen display adds Apple CarPlay o...   \n",
       "\n",
       "                                                    body  \n",
       "0      Two Oregon mushroom hunters have been rescued ...  \n",
       "1      As of Friday morning, the shooter was still at...  \n",
       "2      One person was killed and two injured in a sho...  \n",
       "3      Updated: Nov. 01, 2024, 10:59 a.m.\\nPublished:...  \n",
       "4      Updated: Nov. 01, 2024, 2:42 p.m.\\nPublished: ...  \n",
       "...                                                  ...  \n",
       "85164  Why you can trust ZDNET: ZDNET independently t...  \n",
       "85165  Why you can trust ZDNET: ZDNET's expert staff ...  \n",
       "85166  Why you can trust ZDNET: ZDNET independently t...  \n",
       "85167  Why you can trust ZDNET: ZDNET independently t...  \n",
       "85168  Why you can trust ZDNET: ZDNET's expert staff ...  \n",
       "\n",
       "[85169 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_24_11 = sources_24_11.merge(text_24_11, on = \"textID\", how = \"inner\") # join sources dataframe with their corresponding article content using the textIDs, keeping only the articles where text IDs match. How = left to ensure that it is a dataframe and series, not a list\n",
    "merged_24_11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863ca3f-976f-46ab-9940-1e8d85ffeece",
   "metadata": {},
   "source": [
    "# 20-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239d785-a7c6-4199-bd97-403b3fd5bf6c",
   "metadata": {},
   "source": [
    "## Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3dbb2c-e2b6-494b-b4ea-561d9a312ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          textID                                               body\n",
      "0       32188714  This Halloween, a new generation of hosts are ...\n",
      "1       32188715  Twenty-five years before he was elected presid...\n",
      "2       32188716  Four years ago, I did n't have a plan. Donald ...\n",
      "3       32188719  The HSE said that while evidence is emerging o...\n",
      "4       32188800  SAN JOSE -- A San Jose police officer pleaded ...\n",
      "...          ...                                                ...\n",
      "132326  86347289  Get the Morning Brief sent directly to your in...\n",
      "132327  86347291  The Transportation Security Administration, or...\n",
      "132328  86347296  The new rules are \" like booby traps \" for the...\n",
      "132329  86347298  This Rutgers season has arrived to the point t...\n",
      "132330  86347299  Supporters of President Trump protesting in La...\n",
      "\n",
      "[132331 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# List of file paths to process\n",
    "file_paths = [\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-20-11/20-11-us1.txt\",  # Replace with your actual file names\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-20-11/20-11-us2.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-20-11/20-11-us3.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-20-11/20-11-us4.txt\",\n",
    "    \"/work/LauraSørineVoldgaard#8191/data/text/text-20-11/20-11-us5.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each file\n",
    "all_texts = []\n",
    "\n",
    "# Loop through the list of files\n",
    "for file_path in file_paths:\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "        # Preprocess the text\n",
    "        sample = raw_text\n",
    "        sample = re.sub(r\" ([.,?!':])\", r\"\\1\", sample)  # Remove spaces before punctuation\n",
    "        sample = re.sub(r\"@ @ @ @ @ @ @ @ @ @\", \"CENSOREDfrfrfr\", sample)  # Replace the chosen censor keyword\n",
    "\n",
    "        # Split the text into articles based on '@@' markers\n",
    "        article_ids = re.findall(r\"@@(\\d+)\", sample)  # Extract all article IDs\n",
    "        articles = re.split(r'\"?@@\\d+ ', sample)[1:]  # Split articles by article IDs\n",
    "        articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles]  # Process article content\n",
    "\n",
    "        # Check if the number of IDs matches the number of articles\n",
    "        if len(article_ids) == len(articles):\n",
    "            # Create a dataframe with textIDs and article contents\n",
    "            text = pd.DataFrame(data=dict(textID=article_ids, body=articles))\n",
    "            text[\"textID\"] = text[\"textID\"].astype(int)  # Convert textID to integer for merging compatibility\n",
    "            all_texts.append(text)  # Append the dataframe to the list\n",
    "        else:\n",
    "            # Handle mismatch between IDs and articles\n",
    "            print(f\"Mismatch in IDs and articles in file: {file_path}\")\n",
    "            print(f\"Number of IDs: {len(article_ids)}, Number of Articles: {len(articles)}\")\n",
    "\n",
    "            # Debug the mismatch\n",
    "            for idx, (article_id, article_body) in enumerate(zip(article_ids, articles)):\n",
    "                if article_body.strip() == \"\":  # Check for empty article bodies\n",
    "                    print(f\"Empty article body detected for textID @@{article_id}\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no empty bodies, identify extra IDs or articles\n",
    "                if len(article_ids) > len(articles):\n",
    "                    print(f\"Extra textID found: @@{article_ids[len(articles)]}\")\n",
    "                elif len(articles) > len(article_ids):\n",
    "                    print(f\"Extra article body detected: {articles[len(article_ids)]}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist or is not a valid '.txt' file: {file_path}\")\n",
    "\n",
    "# Concatenate all dataframes from the all_texts list into one dataframe\n",
    "text_20_11 = pd.concat(all_texts, ignore_index=True)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(text_20_11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf70f38-513e-4a2e-a2e5-a7e83379c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32188665</td>\n",
       "      <td>176</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>https://amp.theguardian.com/environment/2020/o...</td>\n",
       "      <td>Chameleon last seen a century ago rediscovered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32188666</td>\n",
       "      <td>803</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>https://amp.theguardian.com/world/live/2020/oc...</td>\n",
       "      <td>Italian cases jump by 31,000 in a day - as it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32188667</td>\n",
       "      <td>756</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/what-t...</td>\n",
       "      <td>Opinion | What Trump and Biden's travel schedu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32188714</td>\n",
       "      <td>1269</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/2020/10/30/arts/televi...</td>\n",
       "      <td>TV's Horror Hosts: 70 Years of Screams and Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32188715</td>\n",
       "      <td>1543</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/2020/10/30/business/tr...</td>\n",
       "      <td>How a Century of Real-Estate Tax Breaks Enrich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162005</th>\n",
       "      <td>86347342</td>\n",
       "      <td>128</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/letter...</td>\n",
       "      <td>The red wolves can breathe new life into Virgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162006</th>\n",
       "      <td>86347343</td>\n",
       "      <td>706</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>https://www.washingtonpost.com/politics/un-pan...</td>\n",
       "      <td>UN: Pandemic to fan surge in humanitarian need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162007</th>\n",
       "      <td>86347346</td>\n",
       "      <td>1031</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>WLWT</td>\n",
       "      <td>https://www.wlwt.com/article/nbc-announces-lin...</td>\n",
       "      <td>NBC announces lineup of Christmas, holiday spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162008</th>\n",
       "      <td>86347351</td>\n",
       "      <td>443</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>ZDNet</td>\n",
       "      <td>https://www.zdnet.com/article/ai-approach-coul...</td>\n",
       "      <td>AI approach could solve the problem of ROI for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162009</th>\n",
       "      <td>86347352</td>\n",
       "      <td>732</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>ZDNet</td>\n",
       "      <td>https://www.zdnet.com/article/vmware-plots-mod...</td>\n",
       "      <td>VMware plots 'modern network' strategy with Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162010 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  words      date country              source  \\\n",
       "0       32188665    176  20-11-01      US     theguardian.com   \n",
       "1       32188666    803  20-11-01      US     theguardian.com   \n",
       "2       32188667    756  20-11-01      US  washingtonpost.com   \n",
       "3       32188714   1269  20-11-01      US         nytimes.com   \n",
       "4       32188715   1543  20-11-01      US         nytimes.com   \n",
       "...          ...    ...       ...     ...                 ...   \n",
       "162005  86347342    128  20-11-30      US     Washington Post   \n",
       "162006  86347343    706  20-11-30      US     Washington Post   \n",
       "162007  86347346   1031  20-11-30      US                WLWT   \n",
       "162008  86347351    443  20-11-30      US               ZDNet   \n",
       "162009  86347352    732  20-11-30      US               ZDNet   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://amp.theguardian.com/environment/2020/o...   \n",
       "1       https://amp.theguardian.com/world/live/2020/oc...   \n",
       "2       https://www.washingtonpost.com/opinions/what-t...   \n",
       "3       https://www.nytimes.com/2020/10/30/arts/televi...   \n",
       "4       https://www.nytimes.com/2020/10/30/business/tr...   \n",
       "...                                                   ...   \n",
       "162005  https://www.washingtonpost.com/opinions/letter...   \n",
       "162006  https://www.washingtonpost.com/politics/un-pan...   \n",
       "162007  https://www.wlwt.com/article/nbc-announces-lin...   \n",
       "162008  https://www.zdnet.com/article/ai-approach-coul...   \n",
       "162009  https://www.zdnet.com/article/vmware-plots-mod...   \n",
       "\n",
       "                                                 headline  \n",
       "0       Chameleon last seen a century ago rediscovered...  \n",
       "1       Italian cases jump by 31,000 in a day - as it ...  \n",
       "2       Opinion | What Trump and Biden's travel schedu...  \n",
       "3       TV's Horror Hosts: 70 Years of Screams and Che...  \n",
       "4       How a Century of Real-Estate Tax Breaks Enrich...  \n",
       "...                                                   ...  \n",
       "162005  The red wolves can breathe new life into Virgi...  \n",
       "162006  UN: Pandemic to fan surge in humanitarian need...  \n",
       "162007  NBC announces lineup of Christmas, holiday spe...  \n",
       "162008  AI approach could solve the problem of ROI for...  \n",
       "162009  VMware plots 'modern network' strategy with Pr...  \n",
       "\n",
       "[162010 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv so you don't have to run all the above again\n",
    "file_path = \"/work/LauraSørineVoldgaard#8191/data/2020_sources/sources-20-11.csv\"\n",
    "sources_20_11 = pd.read_csv(file_path)\n",
    "sources_20_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cd6a4fd-911f-44d4-af6f-e12b13a84d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID     int64\n",
      "body      object\n",
      "dtype: object\n",
      "textID       int64\n",
      "words        int64\n",
      "date        object\n",
      "country     object\n",
      "source      object\n",
      "url         object\n",
      "headline    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'textID' to integers\n",
    "text_20_11['textID'] = text_20_11['textID'].astype(int)\n",
    "sources_20_11['textID'] = sources_20_11['textID'].astype(int)\n",
    "\n",
    "\n",
    "# Verify the data type\n",
    "print(text_20_11.dtypes)  # 'textID' should now be int64\n",
    "print(sources_20_11.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d9ce87-a798-46d6-99d3-4b55c4ab2186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32188665</td>\n",
       "      <td>176</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>https://amp.theguardian.com/environment/2020/o...</td>\n",
       "      <td>Chameleon last seen a century ago rediscovered...</td>\n",
       "      <td>Scientists have found an elusive chameleon spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32188666</td>\n",
       "      <td>803</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>https://amp.theguardian.com/world/live/2020/oc...</td>\n",
       "      <td>Italian cases jump by 31,000 in a day - as it ...</td>\n",
       "      <td>England is expected to go into national lockdo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32188714</td>\n",
       "      <td>1269</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/2020/10/30/arts/televi...</td>\n",
       "      <td>TV's Horror Hosts: 70 Years of Screams and Che...</td>\n",
       "      <td>This Halloween, a new generation of hosts are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32188715</td>\n",
       "      <td>1543</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/2020/10/30/business/tr...</td>\n",
       "      <td>How a Century of Real-Estate Tax Breaks Enrich...</td>\n",
       "      <td>Twenty-five years before he was elected presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32188716</td>\n",
       "      <td>2424</td>\n",
       "      <td>20-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/2020/10/31/your-money/...</td>\n",
       "      <td>Investing for the Future in the United States ...</td>\n",
       "      <td>Four years ago, I did n't have a plan. Donald ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130948</th>\n",
       "      <td>86347342</td>\n",
       "      <td>128</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/letter...</td>\n",
       "      <td>The red wolves can breathe new life into Virgi...</td>\n",
       "      <td>I am pleased to read there is talk of reintrod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130949</th>\n",
       "      <td>86347343</td>\n",
       "      <td>706</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>https://www.washingtonpost.com/politics/un-pan...</td>\n",
       "      <td>UN: Pandemic to fan surge in humanitarian need...</td>\n",
       "      <td>By Associated Press\\nDecember 1, 2020 at 12:02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130950</th>\n",
       "      <td>86347346</td>\n",
       "      <td>1031</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>WLWT</td>\n",
       "      <td>https://www.wlwt.com/article/nbc-announces-lin...</td>\n",
       "      <td>NBC announces lineup of Christmas, holiday spe...</td>\n",
       "      <td>NBC has announced its holiday lineup, complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130951</th>\n",
       "      <td>86347351</td>\n",
       "      <td>443</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>ZDNet</td>\n",
       "      <td>https://www.zdnet.com/article/ai-approach-coul...</td>\n",
       "      <td>AI approach could solve the problem of ROI for...</td>\n",
       "      <td>COVID has created CENSOREDfrfrfr\\nPhoto: Tom F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130952</th>\n",
       "      <td>86347352</td>\n",
       "      <td>732</td>\n",
       "      <td>20-11-30</td>\n",
       "      <td>US</td>\n",
       "      <td>ZDNet</td>\n",
       "      <td>https://www.zdnet.com/article/vmware-plots-mod...</td>\n",
       "      <td>VMware plots 'modern network' strategy with Pr...</td>\n",
       "      <td>In Tanzu, VMware is announcing a new attribute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130953 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  words      date country           source  \\\n",
       "0       32188665    176  20-11-01      US  theguardian.com   \n",
       "1       32188666    803  20-11-01      US  theguardian.com   \n",
       "2       32188714   1269  20-11-01      US      nytimes.com   \n",
       "3       32188715   1543  20-11-01      US      nytimes.com   \n",
       "4       32188716   2424  20-11-01      US      nytimes.com   \n",
       "...          ...    ...       ...     ...              ...   \n",
       "130948  86347342    128  20-11-30      US  Washington Post   \n",
       "130949  86347343    706  20-11-30      US  Washington Post   \n",
       "130950  86347346   1031  20-11-30      US             WLWT   \n",
       "130951  86347351    443  20-11-30      US            ZDNet   \n",
       "130952  86347352    732  20-11-30      US            ZDNet   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://amp.theguardian.com/environment/2020/o...   \n",
       "1       https://amp.theguardian.com/world/live/2020/oc...   \n",
       "2       https://www.nytimes.com/2020/10/30/arts/televi...   \n",
       "3       https://www.nytimes.com/2020/10/30/business/tr...   \n",
       "4       https://www.nytimes.com/2020/10/31/your-money/...   \n",
       "...                                                   ...   \n",
       "130948  https://www.washingtonpost.com/opinions/letter...   \n",
       "130949  https://www.washingtonpost.com/politics/un-pan...   \n",
       "130950  https://www.wlwt.com/article/nbc-announces-lin...   \n",
       "130951  https://www.zdnet.com/article/ai-approach-coul...   \n",
       "130952  https://www.zdnet.com/article/vmware-plots-mod...   \n",
       "\n",
       "                                                 headline  \\\n",
       "0       Chameleon last seen a century ago rediscovered...   \n",
       "1       Italian cases jump by 31,000 in a day - as it ...   \n",
       "2       TV's Horror Hosts: 70 Years of Screams and Che...   \n",
       "3       How a Century of Real-Estate Tax Breaks Enrich...   \n",
       "4       Investing for the Future in the United States ...   \n",
       "...                                                   ...   \n",
       "130948  The red wolves can breathe new life into Virgi...   \n",
       "130949  UN: Pandemic to fan surge in humanitarian need...   \n",
       "130950  NBC announces lineup of Christmas, holiday spe...   \n",
       "130951  AI approach could solve the problem of ROI for...   \n",
       "130952  VMware plots 'modern network' strategy with Pr...   \n",
       "\n",
       "                                                     body  \n",
       "0       Scientists have found an elusive chameleon spe...  \n",
       "1       England is expected to go into national lockdo...  \n",
       "2       This Halloween, a new generation of hosts are ...  \n",
       "3       Twenty-five years before he was elected presid...  \n",
       "4       Four years ago, I did n't have a plan. Donald ...  \n",
       "...                                                   ...  \n",
       "130948  I am pleased to read there is talk of reintrod...  \n",
       "130949  By Associated Press\\nDecember 1, 2020 at 12:02...  \n",
       "130950  NBC has announced its holiday lineup, complete...  \n",
       "130951  COVID has created CENSOREDfrfrfr\\nPhoto: Tom F...  \n",
       "130952  In Tanzu, VMware is announcing a new attribute...  \n",
       "\n",
       "[130953 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_20_11 = sources_20_11.merge(text_20_11, on = \"textID\", how = \"inner\") # join sources dataframe with their corresponding article content using the textIDs, keeping only the articles where text IDs match. How = left to ensure that it is a dataframe and series, not a list\n",
    "merged_20_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26965cfc-b7b5-4ed7-b7e6-21b79d9a5872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
